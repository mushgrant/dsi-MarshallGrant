{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello,\n",
      "I saw your contact information on LinkedIn. I have carefully read through your profile and you seem to have an outstanding personality. This is one major reason why I am in contact with you. My name is Mr. Valery Grayfer Chairman of the Board of Directors of PJSC \"LUKOIL\". I am 86 years old and I was diagnosed with cancer 2 years ago. I will be going in for an operation later this week. I decided to WILL/Donate the sum of 8,750,000.00 Euros(Eight Million Seven Hundred And Fifty Thousand Euros Only etc. etc.\n",
      "\n",
      "\n",
      "\n",
      "Hello,\n",
      "I am writing in regards to your application to the position of Data Scientist at Hooli X. We are pleased to inform you that you passed the first round of interviews and we would like to invite you for an on-site interview with our Senior Data Scientist Mr. John Smith. You will find attached to this message further information on date, time and location of the interview. Please let me know if I can be of any further assistance. Best Regards.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spam = \"\"\"\n",
    "Hello,\\nI saw your contact information on LinkedIn. I have carefully read through your profile and you seem to have an outstanding personality. This is one major reason why I am in contact with you. My name is Mr. Valery Grayfer Chairman of the Board of Directors of PJSC \"LUKOIL\". I am 86 years old and I was diagnosed with cancer 2 years ago. I will be going in for an operation later this week. I decided to WILL/Donate the sum of 8,750,000.00 Euros(Eight Million Seven Hundred And Fifty Thousand Euros Only etc. etc.\n",
    "\"\"\"\n",
    "\n",
    "ham = \"\"\"\n",
    "Hello,\\nI am writing in regards to your application to the position of Data Scientist at Hooli X. We are pleased to inform you that you passed the first round of interviews and we would like to invite you for an on-site interview with our Senior Data Scientist Mr. John Smith. You will find attached to this message further information on date, time and location of the interview. Please let me know if I can be of any further assistance. Best Regards.\n",
    "\"\"\"\n",
    "print spam\n",
    "print\n",
    "print ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec = CountVectorizer()\n",
    "cvec.fit([spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'i': 7, 'of': 4, 'and': 3, 'is': 2, 'etc.': 2, 'am': 2, 'an': 2, 'have': 2, 'in': 2, 'your': 2, 'to': 2, 'years': 2, 'with': 2, 'this': 2, 'contact': 2, 'the': 2, 'major': 1, 'old': 1, 'cancer': 1, 'outstanding': 1, 'seven': 1, 'decided': 1, 'through': 1, 'carefully': 1, 'euros(eight': 1, 'seem': 1, 'saw': 1, 'information': 1, 'for': 1, 'euros': 1, 'fifty': 1, '86': 1, 'sum': 1, '\"lukoil\".': 1, 'only': 1, 'pjsc': 1, 'mr.': 1, '2': 1, 'linkedin.': 1, 'will/donate': 1, 'you': 1, 'hundred': 1, 'was': 1, 'personality.': 1, 'chairman': 1, 'profile': 1, 'you.': 1, 'hello,': 1, 'ago.': 1, 'read': 1, 'going': 1, 'thousand': 1, 'million': 1, 'grayfer': 1, 'reason': 1, 'be': 1, 'one': 1, 'why': 1, 'on': 1, 'name': 1, 'week.': 1, '8,750,000.00': 1, 'later': 1, 'board': 1, 'operation': 1, 'will': 1, 'directors': 1, 'diagnosed': 1, 'valery': 1, 'my': 1})\n",
      "\n",
      "Counter({'to': 5, 'you': 4, 'of': 4, 'the': 3, 'and': 2, 'we': 2, 'scientist': 2, 'data': 2, 'i': 2, 'further': 2, 'this': 1, 'regards.': 1, 'find': 1, 'information': 1, 'am': 1, 'an': 1, 'at': 1, 'in': 1, 'our': 1, 'message': 1, 'pleased': 1, 'best': 1, 'if': 1, 'will': 1, 'would': 1, 'with': 1, 'interviews': 1, 'please': 1, 'writing': 1, 'application': 1, 'mr.': 1, 'location': 1, 'passed': 1, 'interview': 1, 'for': 1, 'john': 1, 'date,': 1, 'be': 1, 'hello,': 1, 'x.': 1, 'invite': 1, 'that': 1, 'any': 1, 'interview.': 1, 'regards': 1, 'let': 1, 'know': 1, 'hooli': 1, 'on-site': 1, 'me': 1, 'on': 1, 'your': 1, 'like': 1, 'assistance.': 1, 'attached': 1, 'senior': 1, 'inform': 1, 'smith.': 1, 'can': 1, 'time': 1, 'position': 1, 'first': 1, 'round': 1, 'are': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print Counter(spam.lower().split())\n",
    "print\n",
    "print Counter(ham.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>750</th>\n",
       "      <th>86</th>\n",
       "      <th>ago</th>\n",
       "      <th>am</th>\n",
       "      <th>an</th>\n",
       "      <th>and</th>\n",
       "      <th>be</th>\n",
       "      <th>board</th>\n",
       "      <th>...</th>\n",
       "      <th>to</th>\n",
       "      <th>valery</th>\n",
       "      <th>was</th>\n",
       "      <th>week</th>\n",
       "      <th>why</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  750  86  ago  am  an  and  be  board  ...   to  valery  was  week  \\\n",
       "0   1    1    1   1    1   2   2    3   1      1  ...    2       1    1     1   \n",
       "\n",
       "   why  will  with  years  you  your  \n",
       "0    1     2     2      2    2     2  \n",
       "\n",
       "[1 rows x 69 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.DataFrame(cvec.transform([spam]).todense(),\n",
    "             columns=cvec.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mDEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\u001b[0m\n",
      "alabaster (0.7.9)\n",
      "anaconda-clean (1.0)\n",
      "anaconda-client (1.5.1)\n",
      "anaconda-navigator (1.3.1)\n",
      "appnope (0.1.0)\n",
      "appscript (1.0.1)\n",
      "argcomplete (1.0.0)\n",
      "astroid (1.4.7)\n",
      "astropy (1.2.1)\n",
      "Babel (2.3.4)\n",
      "backports-abc (0.4)\n",
      "backports.shutil-get-terminal-size (1.0.0)\n",
      "backports.ssl-match-hostname (3.4.0.2)\n",
      "beautifulsoup4 (4.5.1)\n",
      "bitarray (0.8.1)\n",
      "blaze (0.10.1)\n",
      "bokeh (0.12.2)\n",
      "boto (2.42.0)\n",
      "Bottleneck (1.1.0)\n",
      "CacheControl (0.11.7)\n",
      "cdecimal (2.3)\n",
      "certifi (2015.4.28)\n",
      "cffi (1.7.0)\n",
      "chest (0.2.3)\n",
      "click (6.6)\n",
      "cloudpickle (0.2.1)\n",
      "clyent (1.2.2)\n",
      "colorama (0.3.7)\n",
      "conda (4.2.13)\n",
      "conda-build (2.0.2)\n",
      "configobj (5.0.6)\n",
      "configparser (3.5.0)\n",
      "contextlib2 (0.5.3)\n",
      "cryptography (1.5)\n",
      "cycler (0.10.0)\n",
      "Cython (0.24.1)\n",
      "cytoolz (0.8.0)\n",
      "dask (0.11.0)\n",
      "datashape (0.5.2)\n",
      "decorator (4.0.2)\n",
      "dill (0.2.5)\n",
      "docutils (0.12)\n",
      "dynd (0.7.3.dev1)\n",
      "enum34 (1.1.6)\n",
      "et-xmlfile (1.0.1)\n",
      "factual-api (1.7.0)\n",
      "fastcache (1.0.2)\n",
      "filelock (2.0.6)\n",
      "Flask (0.11.1)\n",
      "Flask-Cors (2.1.2)\n",
      "funcsigs (0.4)\n",
      "functools32 (3.2.3.post2)\n",
      "futures (3.0.5)\n",
      "gevent (1.1.2)\n",
      "gnureadline (6.3.3)\n",
      "graphviz (0.5.1)\n",
      "greenlet (0.4.10)\n",
      "grin (1.2.1)\n",
      "h5py (2.6.0)\n",
      "HeapDict (1.0.0)\n",
      "idna (2.1)\n",
      "imagesize (0.7.1)\n",
      "imdbpie (4.2.0)\n",
      "ipaddress (1.0.16)\n",
      "ipykernel (4.0.3)\n",
      "ipython (4.0.0)\n",
      "ipython-genutils (0.1.0)\n",
      "ipywidgets (5.2.2)\n",
      "itsdangerous (0.24)\n",
      "jdcal (1.2)\n",
      "jedi (0.9.0)\n",
      "Jinja2 (2.8)\n",
      "jsonschema (2.5.1)\n",
      "jupyter (1.0.0)\n",
      "jupyter-client (4.0.0)\n",
      "jupyter-console (5.0.0)\n",
      "jupyter-core (4.0.4)\n",
      "lazy-object-proxy (1.2.1)\n",
      "llvmlite (0.13.0)\n",
      "locket (0.2.0)\n",
      "lockfile (0.12.2)\n",
      "lxml (3.6.4)\n",
      "Markdown (2.6.7)\n",
      "MarkupSafe (0.23)\n",
      "matplotlib (1.4.3)\n",
      "mechanize (0.2.5)\n",
      "mistune (0.7.1)\n",
      "mock (1.3.0)\n",
      "mpmath (0.19)\n",
      "multipledispatch (0.4.8)\n",
      "nb-anacondacloud (1.2.0)\n",
      "nb-conda (2.0.0)\n",
      "nb-conda-kernels (2.0.0)\n",
      "nbconvert (4.0.0)\n",
      "nbformat (4.0.0)\n",
      "nbpresent (3.0.2)\n",
      "networkx (1.11)\n",
      "nltk (3.2.1)\n",
      "nose (1.3.7)\n",
      "notebook (4.0.4)\n",
      "numba (0.28.1+0.gfe99fbc.dirty)\n",
      "numexpr (2.6.1)\n",
      "numpy (1.11.2)\n",
      "oauthlib (2.0.1)\n",
      "odo (0.5.0)\n",
      "openpyxl (2.3.2)\n",
      "pandas (0.19.1)\n",
      "partd (0.3.6)\n",
      "path.py (7.7)\n",
      "pathlib2 (2.1.0)\n",
      "patsy (0.4.0)\n",
      "pbr (1.6.0)\n",
      "pep8 (1.7.0)\n",
      "pexpect (3.3)\n",
      "pickleshare (0.5)\n",
      "Pillow (3.3.1)\n",
      "pip (9.0.1)\n",
      "pkginfo (1.3.2)\n",
      "plotly (1.12.9)\n",
      "ply (3.9)\n",
      "port (0.3.3)\n",
      "prompt-toolkit (1.0.3)\n",
      "psutil (4.3.1)\n",
      "psycopg2 (2.6.2)\n",
      "ptyprocess (0.5)\n",
      "py (1.4.31)\n",
      "py-gfm (0.1.3)\n",
      "pyasn1 (0.1.9)\n",
      "PyAudio (0.2.7)\n",
      "pycosat (0.6.1)\n",
      "pycparser (2.14)\n",
      "pycrypto (2.6.1)\n",
      "pycurl (7.43.0)\n",
      "pydotplus (2.0.2)\n",
      "pyflakes (1.3.0)\n",
      "Pygments (2.0.2)\n",
      "pylint (1.5.4)\n",
      "pyOpenSSL (16.0.0)\n",
      "pyparsing (2.0.3)\n",
      "PyRSS2Gen (1.1)\n",
      "pytest (2.9.2)\n",
      "python-dateutil (2.6.0)\n",
      "pytz (2016.10)\n",
      "PyYAML (3.12)\n",
      "pyzmq (14.7.0)\n",
      "QtAwesome (0.3.3)\n",
      "qtconsole (4.2.1)\n",
      "QtPy (1.1.2)\n",
      "redis (2.10.5)\n",
      "requests (2.11.1)\n",
      "requests-oauthlib (0.7.0)\n",
      "rope (0.9.4)\n",
      "ruamel-yaml (-VERSION)\n",
      "scikit-image (0.12.3)\n",
      "scikit-learn (0.16.1)\n",
      "scipy (0.16.0)\n",
      "seaborn (0.6.0)\n",
      "setuptools (27.2.0)\n",
      "simplegeneric (0.8.1)\n",
      "singledispatch (3.4.0.3)\n",
      "six (1.10.0)\n",
      "snowballstemmer (1.2.1)\n",
      "sockjs-tornado (1.0.3)\n",
      "Sphinx (1.4.6)\n",
      "spyder (3.0.0)\n",
      "SQLAlchemy (1.0.13)\n",
      "statsmodels (0.6.1)\n",
      "sympy (1.0)\n",
      "tables (3.2.3.1)\n",
      "terminado (0.5)\n",
      "toolz (0.8.0)\n",
      "tornado (4.2.1)\n",
      "traitlets (4.0.0)\n",
      "unicodecsv (0.14.1)\n",
      "vincent (0.4.4)\n",
      "wcwidth (0.1.7)\n",
      "Werkzeug (0.11.11)\n",
      "wheel (0.29.0)\n",
      "Whoosh (2.7.4)\n",
      "widgetsnbextension (1.2.6)\n",
      "wrapt (1.10.6)\n",
      "xlrd (1.0.0)\n",
      "XlsxWriter (0.9.3)\n",
      "xlwings (0.10.0)\n",
      "xlwt (1.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>of</th>\n",
       "      <th>and</th>\n",
       "      <th>your</th>\n",
       "      <th>contact</th>\n",
       "      <th>is</th>\n",
       "      <th>in</th>\n",
       "      <th>have</th>\n",
       "      <th>euros</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   of  and  your  contact  is  in  have  euros  the  this\n",
       "0   4    3     2        2   2   2     2      2    2     2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transpose().sort_values(0, ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashingVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "         dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
       "         lowercase=True, n_features=1048576, ngram_range=(1, 1),\n",
       "         non_negative=False, norm=u'l2', preprocessor=None,\n",
       "         stop_words=None, strip_accents=None,\n",
       "         token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "hvec = HashingVectorizer()\n",
    "hvec.fit([spam])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1048566</th>\n",
       "      <th>1048567</th>\n",
       "      <th>1048568</th>\n",
       "      <th>1048569</th>\n",
       "      <th>1048570</th>\n",
       "      <th>1048571</th>\n",
       "      <th>1048572</th>\n",
       "      <th>1048573</th>\n",
       "      <th>1048574</th>\n",
       "      <th>1048575</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1048576 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1        2        3        4        5        6        7        \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   8        9         ...     1048566  1048567  1048568  1048569  1048570  \\\n",
       "0      0.0      0.0   ...         0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   1048571  1048572  1048573  1048574  1048575  \n",
       "0      0.0      0.0      0.0      0.0      0.0  \n",
       "\n",
       "[1 rows x 1048576 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.DataFrame(hvec.transform([spam]).todense())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>479532</th>\n",
       "      <th>144749</th>\n",
       "      <th>174171</th>\n",
       "      <th>832412</th>\n",
       "      <th>828689</th>\n",
       "      <th>994433</th>\n",
       "      <th>1005907</th>\n",
       "      <th>170062</th>\n",
       "      <th>675997</th>\n",
       "      <th>959146</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.338062</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.169031</td>\n",
       "      <td>0.084515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    479532    144749    174171    832412    828689    994433    1005907  \\\n",
       "0  0.338062  0.169031  0.169031  0.169031  0.169031  0.169031  0.169031   \n",
       "\n",
       "    170062    675997    959146   \n",
       "0  0.169031  0.169031  0.084515  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transpose().sort_values(0, ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "easy_text = \"I went to the zoo today. What do you think of that? I bet you hate it! Or maybe you don't\"\n",
    "\n",
    "easy_split_text = [\"I went to the zoo today.\",\n",
    "                   \"What do you think of that?\",\n",
    "                   \"I bet you hate it!\",\n",
    "                   \"Or maybe you don't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I went to the zoo today.',\n",
       " 'What do you think of that?',\n",
       " 'I bet you hate it!',\n",
       " \"Or maybe you don't\"]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "sent_detector = PunktSentenceTokenizer()\n",
    "sent_detector.sentences_from_text(easy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swim\n",
      "Swim\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "print stemmer.stem('Swimmed')\n",
    "print stemmer.stem('Swimming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "tvec.fit([spam, ham])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>years</th>\n",
       "      <th>euros</th>\n",
       "      <th>contact</th>\n",
       "      <th>personality</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>lukoil</th>\n",
       "      <th>major</th>\n",
       "      <th>million</th>\n",
       "      <th>old</th>\n",
       "      <th>operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.287128</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>0.143564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         years     euros   contact  personality  linkedin    lukoil     major  \\\n",
       "spam  0.287128  0.287128  0.287128     0.143564  0.143564  0.143564  0.143564   \n",
       "ham   0.000000  0.000000  0.000000     0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "       million       old  operation  \n",
       "spam  0.143564  0.143564   0.143564  \n",
       "ham   0.000000  0.000000   0.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.DataFrame(tvec.transform([spam, ham]).todense(),\n",
    "                   columns=tvec.get_feature_names(),\n",
    "                   index=['spam', 'ham'])\n",
    "\n",
    "df.transpose().sort_values('spam', ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
