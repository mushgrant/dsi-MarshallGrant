{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "cc166dbc-d723-4076-8dd8-a290d911dc9b"
   },
   "source": [
    "# Project 4: Web Scraping Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "59b0deac-55d6-4908-8dee-ce68611486f0"
   },
   "source": [
    "In Project 4, we practice two major skills: collecting data via  web scraping and building a binary predictor with Logistic Regression.\n",
    "\n",
    "We will collect salary information on data science jobs in a variety of markets. Using location, title, and job summary, we'll predict the salary of the job. For job posting sites, this is extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), extrapolating expected salary can help guide negotiations.\n",
    "\n",
    "Normally, we can use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Q: Why would we want this to be a classification problem?\n",
    "- A: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Section one focuses on scraping Indeed.com; then we use listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1321e3c4-2105-428e-9b1b-6d958453ef1d"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9d959074-bf26-4000-b0da-11273e253776"
   },
   "source": [
    "Scrape job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries. First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d9f7b5d1-b227-4bda-a87b-1606b62fb60b"
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "911505d6-159f-4146-967d-a8482fe27e3d"
   },
   "outputs": [],
   "source": [
    "URL = 'http://www.indeed.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "78446809-fa02-48df-b60f-cbeda175a498"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c8846f3e-42a5-4714-9784-fb5d6a28524b"
   },
   "outputs": [],
   "source": [
    "# read site in soup\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "# Append to the full set of results\n",
    "results = soup.findAll('div', { \"class\" : \"result\" })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "963bb376-7746-43ce-98ec-ea4162f7ead6"
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
    "While this has some of the more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "27b6ffb9-b42f-4298-b07a-10e3bab030cd"
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "- Make sure these functions are robust and can handle cases where the data/field may not be available\n",
    "- Test the functions on the results above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "f4b0755f-42e1-438f-89fc-131a60b781cd"
   },
   "outputs": [],
   "source": [
    "# get text\n",
    "def extract_text(el):\n",
    "    if el:\n",
    "        return el.text.strip()\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "# company\n",
    "def get_company_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'company'}))\n",
    "\n",
    "# location\n",
    "def get_location_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'location'}))\n",
    "\n",
    "# summary\n",
    "def get_summary_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'summary'}))\n",
    "# title\n",
    "def get_title_from_result(result):\n",
    "    return extract_text(result.find('a', {'data-tn-element' : 'jobTitle'}))\n",
    "# get salary if exists\n",
    "def get_salary_from_result(result):\n",
    "    salary_table = result.find('td', {'class' : 'snip'})\n",
    "    if salary_table:\n",
    "        snip = salary_table.find('nobr')\n",
    "        if snip:\n",
    "            return snip.text.strip()   \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "dc1d32a3-b13c-4919-8723-ce50dbc7660f"
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
    "There are two query parameters here we can alter to collect more results: the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try different city). The second controls where in the results to start and gives 10 results (so we can keep incrementing this by 10 to move further within the list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "27584c3f-f552-40a2-842a-0681b1fd6265"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and start points. \n",
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "20a34e35-a4db-44eb-8490-9903f8bcf406"
   },
   "outputs": [],
   "source": [
    "# specify city\n",
    "YOUR_CITY = ['Atlanta, GA', 'Los+Angeles, CA', 'Seattle, WA', \n",
    "             'New+York, NY', 'San+Diego, CA', 'San+Francisco, CA', 'Denver CO', 'Boston, MA', 'Austin, TX', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b02e2931-4d5a-4e1e-9504-c6ccaaf84bed"
   },
   "outputs": [],
   "source": [
    "# create template URL and max number of results (pages) to pull\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "\n",
    "# for loop to pull data with bs4\n",
    "for city in set(YOUR_CITY):\n",
    "    for start in range(0, 500, 10 ):\n",
    "        r = requests.get(url_template.format(city, start))\n",
    "        # Grab the results from the request (as above)\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        # Append to the full set of results\n",
    "        results += soup.findAll('div', { \"class\" : \"result\" })\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "10eb5902-4727-4947-a167-2531aa12a427"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "d601ff2f-fbdf-4c4f-8bbe-10c4a3132cc8"
   },
   "outputs": [],
   "source": [
    "# combine data into dictionaries\n",
    "rows = []\n",
    "for result in results:\n",
    "    if result:\n",
    "        row = {'company':get_company_from_result(result),\n",
    "              'location':get_location_from_result(result),\n",
    "              'summary':get_summary_from_result(result),\n",
    "              'title':get_title_from_result(result),\n",
    "               'salary':get_salary_from_result(result)\n",
    "              }\n",
    "        rows.append(row)\n",
    "\n",
    "# create dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6701, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "faac26dc-392a-4f90-a397-144a070702cb"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58ff72c5-eef2-4a86-93ac-22f84ed9b752"
   },
   "outputs": [],
   "source": [
    "# Filter to only the rows that have salary entries\n",
    "df = df.dropna()\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "# Filter out salary entries referring to week, hour or month\n",
    "df_2 = df[~(df.salary.astype('str').str.contains('hour'))] # example\n",
    "df_2 = df[~(df.salary.astype('str').str.contains('week'))]\n",
    "df_2 = df[~(df.salary.astype('str').str.contains('month'))]\n",
    "\n",
    "\n",
    "#reset index\n",
    "df_2 = df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>$140,000 - $160,000 a year</td>\n",
       "      <td>Machine Learning Data Scientist. Forecasting, ...</td>\n",
       "      <td>Senior Machine Learning Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XOR Data Exchange</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>$90,000 a year</td>\n",
       "      <td>XOR is leading a data revolution by giving tra...</td>\n",
       "      <td>Senior Software Engineer/Team Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>$50,000 - $65,000 a year</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volt Workforce Solutions</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>$120,000 - $150,000 a year</td>\n",
       "      <td>Data mining competition experience preferred (...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>$60,000 - $80,000 a year</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>LCMS Certifying Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company    location                      salary  \\\n",
       "0          All-In Analytics  Austin, TX  $140,000 - $160,000 a year   \n",
       "1         XOR Data Exchange  Austin, TX              $90,000 a year   \n",
       "2     Smith Arnold Partners  Austin, TX    $50,000 - $65,000 a year   \n",
       "3  Volt Workforce Solutions  Austin, TX  $120,000 - $150,000 a year   \n",
       "4     Lighthouse Recruiting  Austin, TX    $60,000 - $80,000 a year   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Machine Learning Data Scientist. Forecasting, ...   \n",
       "1  XOR is leading a data revolution by giving tra...   \n",
       "2  Growing international custom research supplier...   \n",
       "3  Data mining competition experience preferred (...   \n",
       "4  Join our Medical Laboratory Scientists Groups:...   \n",
       "\n",
       "                                    title  \n",
       "0  Senior Machine Learning Data Scientist  \n",
       "1      Senior Software Engineer/Team Lead  \n",
       "2                        Research Analyst  \n",
       "3               Machine Learning Engineer  \n",
       "4               LCMS Certifying Scientist  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "e1f58de9-78a7-49c1-b1ff-145a8f983790"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "f2eaea83-8f84-48d3-af17-037538d06601"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def extract_salary_average(salary_string):\n",
    "    regex = r'\\$([0-9]+,[0-9]+)'\n",
    "    matches = re.findall(regex, salary_string)\n",
    "    return np.mean([float(salary.replace(',', '')) for salary in matches ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2d46d846-8aeb-49c3-86ac-768c4fc81552"
   },
   "outputs": [],
   "source": [
    "# use '.map' to transform salary to new feature\n",
    "df_2['salary'] = df_2['salary'].map(extract_salary_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Machine Learning Data Scientist. Forecasting, ...</td>\n",
       "      <td>Senior Machine Learning Data Scientist</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XOR Data Exchange</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>XOR is leading a data revolution by giving tra...</td>\n",
       "      <td>Senior Software Engineer/Team Lead</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volt Workforce Solutions</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Data mining competition experience preferred (...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>LCMS Certifying Scientist</td>\n",
       "      <td>Austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>69673.0</td>\n",
       "      <td>Clean data for analysis. Develop data collecti...</td>\n",
       "      <td>SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10Roof Technology</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Data Scientist, and a UI Developer. Great atti...</td>\n",
       "      <td>Big Data Developer (Spark, Hadoop, Hive)</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mountain Ltd.</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>Enter data from legal sources into database. I...</td>\n",
       "      <td>Legal Research Analyst</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lauren Enterprises</td>\n",
       "      <td>Denver, CO 80226</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Looking for a Food Scientist:. Secondary and/o...</td>\n",
       "      <td>Food Scientist: Chemistry &amp; Formulations</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>Validate data models (logical and physical) fo...</td>\n",
       "      <td>Government Enterprise Architect</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gunther Douglas, Inc.</td>\n",
       "      <td>Superior, CO</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Gunther Douglas’ client is seeking a Data Scie...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Superior</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Community College of Aurora</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Works with large complex data sets, including ...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Aurora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>63339.0</td>\n",
       "      <td>Fulfill internal data requests, and coordinate...</td>\n",
       "      <td>RESEARCH ANALYST – 16996</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Of visiting scientists; In use of excel, data ...</td>\n",
       "      <td>Managing Director for STROBE</td>\n",
       "      <td>Boulder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Denver Health</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>88091.0</td>\n",
       "      <td>Budget development, processing and monitoring ...</td>\n",
       "      <td>Business Manager - RADARS</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Potatoes USA</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Extensive knowledge and experience analyzing s...</td>\n",
       "      <td>Global Marketing Manager - Food Manufacturing</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>50500.0</td>\n",
       "      <td>Experience finding data and/or providing suppo...</td>\n",
       "      <td>Health &amp; Human Sciences Librarian</td>\n",
       "      <td>Boulder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dynamic Staffing Inc.</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Exposure to big data systems (Hadoop, HBASE, H...</td>\n",
       "      <td>Data Scientist-Software Engineer</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LIBERTY MUTUAL GROUP</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>We are searching for a highly motivated data s...</td>\n",
       "      <td>Assistant Director, Data Science</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cutting Edge Medical Diagnostics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Data and image analysis using advanced statist...</td>\n",
       "      <td>Sr. Data Scientist / Machine Learning (In-vitr...</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HERO.Jobs</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Build big data, machine learning applications ...</td>\n",
       "      <td>Machine Learning Engineer - Big Data, Python, R</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G2 Web Services, LLC</td>\n",
       "      <td>Bellevue, WA 98004 (Downtown area)</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Capture and record data in G2’s proprietary so...</td>\n",
       "      <td>Research and Investigation Analyst</td>\n",
       "      <td>Bellevue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Business Intelligence Scientist. SQL, Digital ...</td>\n",
       "      <td>Business Intelligence Scientist</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>State of Washington</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>55548.0</td>\n",
       "      <td>Performing field surveys or studies, 2) respon...</td>\n",
       "      <td>TMDL Lead (Environmental Specialist 4)</td>\n",
       "      <td>Bellevue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>Variant Scientist (Remote)</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>Working with a team of Analysts, Software Deve...</td>\n",
       "      <td>Sr. Global Device Manager</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Seattle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tronc (formerly Tribune Publishing)</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Partner with data scientists in the Technology...</td>\n",
       "      <td>Social Media Marketing Data Analyst</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LT</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Our data team consists of two data analysts an...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Codesmith</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>We are now bringing this same groundbreaking a...</td>\n",
       "      <td>Senior Data Science Engineer and Instructor</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Nathan S. Kline Institute</td>\n",
       "      <td>Orangeburg, NY</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>Additional experience in statistical analysis ...</td>\n",
       "      <td>Post-Doctoral Scientist (Analytical Psychophar...</td>\n",
       "      <td>Orangeburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>Any other experience within data scalability, ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Harnham</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>You will join the data engineering team and wo...</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>101553.5</td>\n",
       "      <td>Assess data for completeness, accuracy, and qu...</td>\n",
       "      <td>Statistician (Health)</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>Junior Data Scientist sought by Fortune 500 co...</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Alpharetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>85399.0</td>\n",
       "      <td>As Behavioral Scientist you will:. Identify an...</td>\n",
       "      <td>Behavioral Scientist</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Stackfolio</td>\n",
       "      <td>Atlanta, GA 30308 (Old Fourth Ward area)</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>We are looking for a bright and experienced da...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Python, data mining, data science; The data Sc...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>85500.0</td>\n",
       "      <td>Staff Scientists will have leadership responsi...</td>\n",
       "      <td>Staff Scientist (Goldsmith Lab)</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>SearchAccountingJobs</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>177500.0</td>\n",
       "      <td>The client is looking for talented individuals...</td>\n",
       "      <td>Lead Quantitative Analyst</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>-Post degree business based experience doing d...</td>\n",
       "      <td>Marketing Statistician</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>The Medical Image Analysis Scientist, works wi...</td>\n",
       "      <td>Scientist, Med Imag Analysis</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Synergy Search Group</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Duties will include data conversion from multi...</td>\n",
       "      <td>Audit Snr (Banking) - Data Analysis 60K-80K</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Georgia Department of Public Health</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Under broad supervision, assists technicians a...</td>\n",
       "      <td>Laboratory Aide 3</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>66700.0</td>\n",
       "      <td>Responsible for post award processing of grant...</td>\n",
       "      <td>Sponsored Research Financial Analyst</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Data Scientist, Supply Chain sought by Fortune...</td>\n",
       "      <td>Data Scientist - Supply Chain</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Dashbot.io</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Data migration, transformation, and scripting....</td>\n",
       "      <td>Data Engineer and Scientist</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Machine Learning Senior Data Scientist. Mentor...</td>\n",
       "      <td>Sr. Machine Learning Data Scientist</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Established retail and eCommerce company in do...</td>\n",
       "      <td>Senior Data Scientist (Optimization)</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Federal Emergency Management Agency</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>96947.0</td>\n",
       "      <td>In this position, you will serve as a Physical...</td>\n",
       "      <td>Physical Scientist</td>\n",
       "      <td>Oakland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Nisum Technologies</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Big Data Stack:. Hadoop data Ingestion, data q...</td>\n",
       "      <td>Big Data Talend Developer</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Elevate Recruiting Group</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Through the Our Clients pivotal world-view in ...</td>\n",
       "      <td>Senior Data Scientist - Security Experience is...</td>\n",
       "      <td>Redwood City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Harnham</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>You will lead a team of 4 data scientists incl...</td>\n",
       "      <td>Senior Data Science Manager</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Data Mining Experience. The Data Engineers wor...</td>\n",
       "      <td>Data Engineer (Python)</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Bayone Solutions Inc.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Position - Data Scientist - Recommendation Eng...</td>\n",
       "      <td>Data Scientist - Recommendation Engine</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>San Francisco Department of Public Health</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>111774.0</td>\n",
       "      <td>Under administrative direction of the Director...</td>\n",
       "      <td>Manager I - Chief Microbiologist</td>\n",
       "      <td>San Francisco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>The Machine Learning Operations group within t...</td>\n",
       "      <td>Lead Data Analyst (Machine Learning Operations...</td>\n",
       "      <td>Berkeley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>Proven experience with Business Intelligence t...</td>\n",
       "      <td>Strategic Research Opportunities Analyst</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>IGE Therapeutics, Inc</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>The candidates working in a Team culture, are ...</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Experience working with large amounts of data....</td>\n",
       "      <td>Software Engineer (C#/Machine Learning)</td>\n",
       "      <td>San Diego</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company  \\\n",
       "0                              All-In Analytics   \n",
       "1                             XOR Data Exchange   \n",
       "2                         Smith Arnold Partners   \n",
       "3                      Volt Workforce Solutions   \n",
       "4                         Lighthouse Recruiting   \n",
       "5                         Denver Public Schools   \n",
       "6                             10Roof Technology   \n",
       "7                                 Mountain Ltd.   \n",
       "8                            Lauren Enterprises   \n",
       "9                           xentity corporation   \n",
       "10                        Gunther Douglas, Inc.   \n",
       "11                  Community College of Aurora   \n",
       "12                        Denver Public Schools   \n",
       "13                       University of Colorado   \n",
       "14                                Denver Health   \n",
       "15                                 Potatoes USA   \n",
       "16                       University of Colorado   \n",
       "17                        Dynamic Staffing Inc.   \n",
       "18                         LIBERTY MUTUAL GROUP   \n",
       "19             Cutting Edge Medical Diagnostics   \n",
       "20                                    HERO.Jobs   \n",
       "21                         G2 Web Services, LLC   \n",
       "22                             All-In Analytics   \n",
       "23                          State of Washington   \n",
       "24                        Lighthouse Recruiting   \n",
       "25                             All-In Analytics   \n",
       "26                        Smith Arnold Partners   \n",
       "27          tronc (formerly Tribune Publishing)   \n",
       "28                                           LT   \n",
       "29                                    Codesmith   \n",
       "..                                          ...   \n",
       "117                   Nathan S. Kline Institute   \n",
       "118                       Workbridge Associates   \n",
       "119                                     Harnham   \n",
       "120  Centers for Disease Control and Prevention   \n",
       "121                         Analytic Recruiting   \n",
       "122  Centers for Disease Control and Prevention   \n",
       "123                                  Stackfolio   \n",
       "124                         Analytic Recruiting   \n",
       "125                            Emory University   \n",
       "126                        SearchAccountingJobs   \n",
       "127                     Smith Hanley Associates   \n",
       "128                            Emory University   \n",
       "129                        Synergy Search Group   \n",
       "130         Georgia Department of Public Health   \n",
       "131                            Emory University   \n",
       "132                         Analytic Recruiting   \n",
       "133                                  Dashbot.io   \n",
       "134                            All-In Analytics   \n",
       "135                       Workbridge Associates   \n",
       "136         Federal Emergency Management Agency   \n",
       "137                          Nisum Technologies   \n",
       "138                    Elevate Recruiting Group   \n",
       "139                                     Harnham   \n",
       "140                       Workbridge Associates   \n",
       "141                       Bayone Solutions Inc.   \n",
       "142   San Francisco Department of Public Health   \n",
       "143                       Workbridge Associates   \n",
       "144                                UC San Diego   \n",
       "145                       IGE Therapeutics, Inc   \n",
       "146                       Workbridge Associates   \n",
       "\n",
       "                                        location    salary  \\\n",
       "0                                     Austin, TX  150000.0   \n",
       "1                                     Austin, TX   90000.0   \n",
       "2                                     Austin, TX   57500.0   \n",
       "3                                     Austin, TX  135000.0   \n",
       "4                                     Austin, TX   70000.0   \n",
       "5    Denver, CO 80204 (Central West Denver area)   69673.0   \n",
       "6                                     Denver, CO  105000.0   \n",
       "7                                     Denver, CO   42500.0   \n",
       "8                               Denver, CO 80226   35000.0   \n",
       "9                                     Denver, CO  111000.0   \n",
       "10                                  Superior, CO  112500.0   \n",
       "11                                    Aurora, CO   40000.0   \n",
       "12                                    Denver, CO   63339.0   \n",
       "13                                   Boulder, CO  107500.0   \n",
       "14   Denver, CO 80204 (Central West Denver area)   88091.0   \n",
       "15                                    Denver, CO   85000.0   \n",
       "16                                   Boulder, CO   50500.0   \n",
       "17                                   Seattle, WA  125000.0   \n",
       "18                                   Seattle, WA  118000.0   \n",
       "19                                   Seattle, WA  140000.0   \n",
       "20                                   Seattle, WA  160000.0   \n",
       "21            Bellevue, WA 98004 (Downtown area)   35000.0   \n",
       "22                                   Seattle, WA  125000.0   \n",
       "23                                  Bellevue, WA   55548.0   \n",
       "24                                   Seattle, WA   95000.0   \n",
       "25                                   Seattle, WA  162500.0   \n",
       "26                                   Seattle, WA   57500.0   \n",
       "27                               Los Angeles, CA   65000.0   \n",
       "28                               Los Angeles, CA  180000.0   \n",
       "29                               Los Angeles, CA  103000.0   \n",
       "..                                           ...       ...   \n",
       "117                               Orangeburg, NY   25000.0   \n",
       "118                                 New York, NY  115000.0   \n",
       "119                                 New York, NY  110000.0   \n",
       "120                                  Atlanta, GA  101553.5   \n",
       "121                               Alpharetta, GA   82500.0   \n",
       "122                                  Atlanta, GA   85399.0   \n",
       "123     Atlanta, GA 30308 (Old Fourth Ward area)   80000.0   \n",
       "124                                  Atlanta, GA  112500.0   \n",
       "125                                  Atlanta, GA   85500.0   \n",
       "126                                  Atlanta, GA  177500.0   \n",
       "127                                  Atlanta, GA   87500.0   \n",
       "128                                  Atlanta, GA   69900.0   \n",
       "129                                  Atlanta, GA   80000.0   \n",
       "130                                  Atlanta, GA   24000.0   \n",
       "131                                  Atlanta, GA   66700.0   \n",
       "132                                  Atlanta, GA  107500.0   \n",
       "133                            San Francisco, CA  170000.0   \n",
       "134                            San Francisco, CA  135000.0   \n",
       "135                            San Francisco, CA  150000.0   \n",
       "136                                  Oakland, CA   96947.0   \n",
       "137                            San Francisco, CA  140000.0   \n",
       "138                             Redwood City, CA  170000.0   \n",
       "139                            San Francisco, CA  185000.0   \n",
       "140                            San Francisco, CA  150000.0   \n",
       "141                            San Francisco, CA  160000.0   \n",
       "142                            San Francisco, CA  111774.0   \n",
       "143                                 Berkeley, CA  155000.0   \n",
       "144                                San Diego, CA   68200.0   \n",
       "145                                San Diego, CA   53000.0   \n",
       "146                                San Diego, CA  100000.0   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Machine Learning Data Scientist. Forecasting, ...   \n",
       "1    XOR is leading a data revolution by giving tra...   \n",
       "2    Growing international custom research supplier...   \n",
       "3    Data mining competition experience preferred (...   \n",
       "4    Join our Medical Laboratory Scientists Groups:...   \n",
       "5    Clean data for analysis. Develop data collecti...   \n",
       "6    Data Scientist, and a UI Developer. Great atti...   \n",
       "7    Enter data from legal sources into database. I...   \n",
       "8    Looking for a Food Scientist:. Secondary and/o...   \n",
       "9    Validate data models (logical and physical) fo...   \n",
       "10   Gunther Douglas’ client is seeking a Data Scie...   \n",
       "11   Works with large complex data sets, including ...   \n",
       "12   Fulfill internal data requests, and coordinate...   \n",
       "13   Of visiting scientists; In use of excel, data ...   \n",
       "14   Budget development, processing and monitoring ...   \n",
       "15   Extensive knowledge and experience analyzing s...   \n",
       "16   Experience finding data and/or providing suppo...   \n",
       "17   Exposure to big data systems (Hadoop, HBASE, H...   \n",
       "18   We are searching for a highly motivated data s...   \n",
       "19   Data and image analysis using advanced statist...   \n",
       "20   Build big data, machine learning applications ...   \n",
       "21   Capture and record data in G2’s proprietary so...   \n",
       "22   Business Intelligence Scientist. SQL, Digital ...   \n",
       "23   Performing field surveys or studies, 2) respon...   \n",
       "24   Join our Medical Laboratory Scientists Groups:...   \n",
       "25   Working with a team of Analysts, Software Deve...   \n",
       "26   Growing international custom research supplier...   \n",
       "27   Partner with data scientists in the Technology...   \n",
       "28   Our data team consists of two data analysts an...   \n",
       "29   We are now bringing this same groundbreaking a...   \n",
       "..                                                 ...   \n",
       "117  Additional experience in statistical analysis ...   \n",
       "118  Any other experience within data scalability, ...   \n",
       "119  You will join the data engineering team and wo...   \n",
       "120  Assess data for completeness, accuracy, and qu...   \n",
       "121  Junior Data Scientist sought by Fortune 500 co...   \n",
       "122  As Behavioral Scientist you will:. Identify an...   \n",
       "123  We are looking for a bright and experienced da...   \n",
       "124  Python, data mining, data science; The data Sc...   \n",
       "125  Staff Scientists will have leadership responsi...   \n",
       "126  The client is looking for talented individuals...   \n",
       "127  -Post degree business based experience doing d...   \n",
       "128  The Medical Image Analysis Scientist, works wi...   \n",
       "129  Duties will include data conversion from multi...   \n",
       "130  Under broad supervision, assists technicians a...   \n",
       "131  Responsible for post award processing of grant...   \n",
       "132  Data Scientist, Supply Chain sought by Fortune...   \n",
       "133  Data migration, transformation, and scripting....   \n",
       "134  Machine Learning Senior Data Scientist. Mentor...   \n",
       "135  Established retail and eCommerce company in do...   \n",
       "136  In this position, you will serve as a Physical...   \n",
       "137  Big Data Stack:. Hadoop data Ingestion, data q...   \n",
       "138  Through the Our Clients pivotal world-view in ...   \n",
       "139  You will lead a team of 4 data scientists incl...   \n",
       "140  Data Mining Experience. The Data Engineers wor...   \n",
       "141  Position - Data Scientist - Recommendation Eng...   \n",
       "142  Under administrative direction of the Director...   \n",
       "143  The Machine Learning Operations group within t...   \n",
       "144  Proven experience with Business Intelligence t...   \n",
       "145  The candidates working in a Team culture, are ...   \n",
       "146  Experience working with large amounts of data....   \n",
       "\n",
       "                                                 title           city  \n",
       "0               Senior Machine Learning Data Scientist         Austin  \n",
       "1                   Senior Software Engineer/Team Lead         Austin  \n",
       "2                                     Research Analyst         Austin  \n",
       "3                            Machine Learning Engineer         Austin  \n",
       "4                            LCMS Certifying Scientist         Austin  \n",
       "5    SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...         Denver  \n",
       "6             Big Data Developer (Spark, Hadoop, Hive)         Denver  \n",
       "7                               Legal Research Analyst         Denver  \n",
       "8             Food Scientist: Chemistry & Formulations         Denver  \n",
       "9                      Government Enterprise Architect         Denver  \n",
       "10                                      Data Scientist       Superior  \n",
       "11                                    Research Analyst         Aurora  \n",
       "12                            RESEARCH ANALYST – 16996         Denver  \n",
       "13                        Managing Director for STROBE        Boulder  \n",
       "14                           Business Manager - RADARS         Denver  \n",
       "15       Global Marketing Manager - Food Manufacturing         Denver  \n",
       "16                   Health & Human Sciences Librarian        Boulder  \n",
       "17                    Data Scientist-Software Engineer        Seattle  \n",
       "18                    Assistant Director, Data Science        Seattle  \n",
       "19   Sr. Data Scientist / Machine Learning (In-vitr...        Seattle  \n",
       "20     Machine Learning Engineer - Big Data, Python, R        Seattle  \n",
       "21                  Research and Investigation Analyst       Bellevue  \n",
       "22                     Business Intelligence Scientist        Seattle  \n",
       "23              TMDL Lead (Environmental Specialist 4)       Bellevue  \n",
       "24                          Variant Scientist (Remote)        Seattle  \n",
       "25                           Sr. Global Device Manager        Seattle  \n",
       "26                                    Research Analyst        Seattle  \n",
       "27                 Social Media Marketing Data Analyst    Los Angeles  \n",
       "28                               Senior Data Scientist    Los Angeles  \n",
       "29         Senior Data Science Engineer and Instructor    Los Angeles  \n",
       "..                                                 ...            ...  \n",
       "117  Post-Doctoral Scientist (Analytical Psychophar...     Orangeburg  \n",
       "118                                     Data Scientist       New York  \n",
       "119                                  Big Data Engineer       New York  \n",
       "120                              Statistician (Health)        Atlanta  \n",
       "121                              Junior Data Scientist     Alpharetta  \n",
       "122                               Behavioral Scientist        Atlanta  \n",
       "123                                Lead Data Scientist        Atlanta  \n",
       "124                              Senior Data Scientist        Atlanta  \n",
       "125                    Staff Scientist (Goldsmith Lab)        Atlanta  \n",
       "126                          Lead Quantitative Analyst        Atlanta  \n",
       "127                             Marketing Statistician        Atlanta  \n",
       "128                       Scientist, Med Imag Analysis        Atlanta  \n",
       "129        Audit Snr (Banking) - Data Analysis 60K-80K        Atlanta  \n",
       "130                                  Laboratory Aide 3        Atlanta  \n",
       "131               Sponsored Research Financial Analyst        Atlanta  \n",
       "132                      Data Scientist - Supply Chain        Atlanta  \n",
       "133                        Data Engineer and Scientist  San Francisco  \n",
       "134                Sr. Machine Learning Data Scientist  San Francisco  \n",
       "135               Senior Data Scientist (Optimization)  San Francisco  \n",
       "136                                 Physical Scientist        Oakland  \n",
       "137                          Big Data Talend Developer  San Francisco  \n",
       "138  Senior Data Scientist - Security Experience is...   Redwood City  \n",
       "139                        Senior Data Science Manager  San Francisco  \n",
       "140                             Data Engineer (Python)  San Francisco  \n",
       "141             Data Scientist - Recommendation Engine  San Francisco  \n",
       "142                   Manager I - Chief Microbiologist  San Francisco  \n",
       "143  Lead Data Analyst (Machine Learning Operations...       Berkeley  \n",
       "144           Strategic Research Opportunities Analyst      San Diego  \n",
       "145                                          Scientist      San Diego  \n",
       "146            Software Engineer (C#/Machine Learning)      San Diego  \n",
       "\n",
       "[147 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "5d66eb8a-a032-43f7-8e87-8f37612c2ce5"
   },
   "outputs": [],
   "source": [
    "# save scraped results as a CSV for Tableau/external viz\n",
    "df_2.to_csv('Df_2Salaries.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "6e8a5a1c-1580-4845-a9b6-482bc00c73cd"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "634ab7c1-c76f-4b04-a36e-5ff3cb1f9eb2"
   },
   "outputs": [],
   "source": [
    "# load in the the data of scraped salaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def city_extract(word):\n",
    "    return word.split(',')[0].split('.')[0].strip()\n",
    "def state_extract(word):\n",
    "    return word.split(',')[1].split(' ')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_2['city'] = pd.DataFrame({'city':df_2['location'].apply(city_extract)})\n",
    "df_2['state'] = pd.DataFrame({'state':df_2['location'].apply(state_extract)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Machine Learning Data Scientist. Forecasting, ...</td>\n",
       "      <td>Senior Machine Learning Data Scientist</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XOR Data Exchange</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>XOR is leading a data revolution by giving tra...</td>\n",
       "      <td>Senior Software Engineer/Team Lead</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volt Workforce Solutions</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Data mining competition experience preferred (...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>LCMS Certifying Scientist</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>69673.0</td>\n",
       "      <td>Clean data for analysis. Develop data collecti...</td>\n",
       "      <td>SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10Roof Technology</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Data Scientist, and a UI Developer. Great atti...</td>\n",
       "      <td>Big Data Developer (Spark, Hadoop, Hive)</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mountain Ltd.</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>Enter data from legal sources into database. I...</td>\n",
       "      <td>Legal Research Analyst</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lauren Enterprises</td>\n",
       "      <td>Denver, CO 80226</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Looking for a Food Scientist:. Secondary and/o...</td>\n",
       "      <td>Food Scientist: Chemistry &amp; Formulations</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>Validate data models (logical and physical) fo...</td>\n",
       "      <td>Government Enterprise Architect</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Gunther Douglas, Inc.</td>\n",
       "      <td>Superior, CO</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Gunther Douglas’ client is seeking a Data Scie...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Superior</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Community College of Aurora</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Works with large complex data sets, including ...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>63339.0</td>\n",
       "      <td>Fulfill internal data requests, and coordinate...</td>\n",
       "      <td>RESEARCH ANALYST – 16996</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Of visiting scientists; In use of excel, data ...</td>\n",
       "      <td>Managing Director for STROBE</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Denver Health</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>88091.0</td>\n",
       "      <td>Budget development, processing and monitoring ...</td>\n",
       "      <td>Business Manager - RADARS</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Potatoes USA</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Extensive knowledge and experience analyzing s...</td>\n",
       "      <td>Global Marketing Manager - Food Manufacturing</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>50500.0</td>\n",
       "      <td>Experience finding data and/or providing suppo...</td>\n",
       "      <td>Health &amp; Human Sciences Librarian</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dynamic Staffing Inc.</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Exposure to big data systems (Hadoop, HBASE, H...</td>\n",
       "      <td>Data Scientist-Software Engineer</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LIBERTY MUTUAL GROUP</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>118000.0</td>\n",
       "      <td>We are searching for a highly motivated data s...</td>\n",
       "      <td>Assistant Director, Data Science</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cutting Edge Medical Diagnostics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Data and image analysis using advanced statist...</td>\n",
       "      <td>Sr. Data Scientist / Machine Learning (In-vitr...</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HERO.Jobs</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Build big data, machine learning applications ...</td>\n",
       "      <td>Machine Learning Engineer - Big Data, Python, R</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G2 Web Services, LLC</td>\n",
       "      <td>Bellevue, WA 98004 (Downtown area)</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Capture and record data in G2’s proprietary so...</td>\n",
       "      <td>Research and Investigation Analyst</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Business Intelligence Scientist. SQL, Digital ...</td>\n",
       "      <td>Business Intelligence Scientist</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>State of Washington</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>55548.0</td>\n",
       "      <td>Performing field surveys or studies, 2) respon...</td>\n",
       "      <td>TMDL Lead (Environmental Specialist 4)</td>\n",
       "      <td>Bellevue</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>Variant Scientist (Remote)</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>Working with a team of Analysts, Software Deve...</td>\n",
       "      <td>Sr. Global Device Manager</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>tronc (formerly Tribune Publishing)</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Partner with data scientists in the Technology...</td>\n",
       "      <td>Social Media Marketing Data Analyst</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LT</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Our data team consists of two data analysts an...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Codesmith</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>We are now bringing this same groundbreaking a...</td>\n",
       "      <td>Senior Data Science Engineer and Instructor</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Nathan S. Kline Institute</td>\n",
       "      <td>Orangeburg, NY</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>Additional experience in statistical analysis ...</td>\n",
       "      <td>Post-Doctoral Scientist (Analytical Psychophar...</td>\n",
       "      <td>Orangeburg</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>Any other experience within data scalability, ...</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Harnham</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>You will join the data engineering team and wo...</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>New York</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>101553.5</td>\n",
       "      <td>Assess data for completeness, accuracy, and qu...</td>\n",
       "      <td>Statistician (Health)</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Alpharetta, GA</td>\n",
       "      <td>82500.0</td>\n",
       "      <td>Junior Data Scientist sought by Fortune 500 co...</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Alpharetta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Centers for Disease Control and Prevention</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>85399.0</td>\n",
       "      <td>As Behavioral Scientist you will:. Identify an...</td>\n",
       "      <td>Behavioral Scientist</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Stackfolio</td>\n",
       "      <td>Atlanta, GA 30308 (Old Fourth Ward area)</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>We are looking for a bright and experienced da...</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Python, data mining, data science; The data Sc...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>85500.0</td>\n",
       "      <td>Staff Scientists will have leadership responsi...</td>\n",
       "      <td>Staff Scientist (Goldsmith Lab)</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>SearchAccountingJobs</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>177500.0</td>\n",
       "      <td>The client is looking for talented individuals...</td>\n",
       "      <td>Lead Quantitative Analyst</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>87500.0</td>\n",
       "      <td>-Post degree business based experience doing d...</td>\n",
       "      <td>Marketing Statistician</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>The Medical Image Analysis Scientist, works wi...</td>\n",
       "      <td>Scientist, Med Imag Analysis</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Synergy Search Group</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Duties will include data conversion from multi...</td>\n",
       "      <td>Audit Snr (Banking) - Data Analysis 60K-80K</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Georgia Department of Public Health</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Under broad supervision, assists technicians a...</td>\n",
       "      <td>Laboratory Aide 3</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>66700.0</td>\n",
       "      <td>Responsible for post award processing of grant...</td>\n",
       "      <td>Sponsored Research Financial Analyst</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Analytic Recruiting</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Data Scientist, Supply Chain sought by Fortune...</td>\n",
       "      <td>Data Scientist - Supply Chain</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Dashbot.io</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Data migration, transformation, and scripting....</td>\n",
       "      <td>Data Engineer and Scientist</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Machine Learning Senior Data Scientist. Mentor...</td>\n",
       "      <td>Sr. Machine Learning Data Scientist</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Established retail and eCommerce company in do...</td>\n",
       "      <td>Senior Data Scientist (Optimization)</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Federal Emergency Management Agency</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>96947.0</td>\n",
       "      <td>In this position, you will serve as a Physical...</td>\n",
       "      <td>Physical Scientist</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Nisum Technologies</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Big Data Stack:. Hadoop data Ingestion, data q...</td>\n",
       "      <td>Big Data Talend Developer</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Elevate Recruiting Group</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Through the Our Clients pivotal world-view in ...</td>\n",
       "      <td>Senior Data Scientist - Security Experience is...</td>\n",
       "      <td>Redwood City</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Harnham</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>You will lead a team of 4 data scientists incl...</td>\n",
       "      <td>Senior Data Science Manager</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Data Mining Experience. The Data Engineers wor...</td>\n",
       "      <td>Data Engineer (Python)</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Bayone Solutions Inc.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Position - Data Scientist - Recommendation Eng...</td>\n",
       "      <td>Data Scientist - Recommendation Engine</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>San Francisco Department of Public Health</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>111774.0</td>\n",
       "      <td>Under administrative direction of the Director...</td>\n",
       "      <td>Manager I - Chief Microbiologist</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>155000.0</td>\n",
       "      <td>The Machine Learning Operations group within t...</td>\n",
       "      <td>Lead Data Analyst (Machine Learning Operations...</td>\n",
       "      <td>Berkeley</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>Proven experience with Business Intelligence t...</td>\n",
       "      <td>Strategic Research Opportunities Analyst</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>IGE Therapeutics, Inc</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>The candidates working in a Team culture, are ...</td>\n",
       "      <td>Scientist</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Experience working with large amounts of data....</td>\n",
       "      <td>Software Engineer (C#/Machine Learning)</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company  \\\n",
       "0                              All-In Analytics   \n",
       "1                             XOR Data Exchange   \n",
       "2                         Smith Arnold Partners   \n",
       "3                      Volt Workforce Solutions   \n",
       "4                         Lighthouse Recruiting   \n",
       "5                         Denver Public Schools   \n",
       "6                             10Roof Technology   \n",
       "7                                 Mountain Ltd.   \n",
       "8                            Lauren Enterprises   \n",
       "9                           xentity corporation   \n",
       "10                        Gunther Douglas, Inc.   \n",
       "11                  Community College of Aurora   \n",
       "12                        Denver Public Schools   \n",
       "13                       University of Colorado   \n",
       "14                                Denver Health   \n",
       "15                                 Potatoes USA   \n",
       "16                       University of Colorado   \n",
       "17                        Dynamic Staffing Inc.   \n",
       "18                         LIBERTY MUTUAL GROUP   \n",
       "19             Cutting Edge Medical Diagnostics   \n",
       "20                                    HERO.Jobs   \n",
       "21                         G2 Web Services, LLC   \n",
       "22                             All-In Analytics   \n",
       "23                          State of Washington   \n",
       "24                        Lighthouse Recruiting   \n",
       "25                             All-In Analytics   \n",
       "26                        Smith Arnold Partners   \n",
       "27          tronc (formerly Tribune Publishing)   \n",
       "28                                           LT   \n",
       "29                                    Codesmith   \n",
       "..                                          ...   \n",
       "117                   Nathan S. Kline Institute   \n",
       "118                       Workbridge Associates   \n",
       "119                                     Harnham   \n",
       "120  Centers for Disease Control and Prevention   \n",
       "121                         Analytic Recruiting   \n",
       "122  Centers for Disease Control and Prevention   \n",
       "123                                  Stackfolio   \n",
       "124                         Analytic Recruiting   \n",
       "125                            Emory University   \n",
       "126                        SearchAccountingJobs   \n",
       "127                     Smith Hanley Associates   \n",
       "128                            Emory University   \n",
       "129                        Synergy Search Group   \n",
       "130         Georgia Department of Public Health   \n",
       "131                            Emory University   \n",
       "132                         Analytic Recruiting   \n",
       "133                                  Dashbot.io   \n",
       "134                            All-In Analytics   \n",
       "135                       Workbridge Associates   \n",
       "136         Federal Emergency Management Agency   \n",
       "137                          Nisum Technologies   \n",
       "138                    Elevate Recruiting Group   \n",
       "139                                     Harnham   \n",
       "140                       Workbridge Associates   \n",
       "141                       Bayone Solutions Inc.   \n",
       "142   San Francisco Department of Public Health   \n",
       "143                       Workbridge Associates   \n",
       "144                                UC San Diego   \n",
       "145                       IGE Therapeutics, Inc   \n",
       "146                       Workbridge Associates   \n",
       "\n",
       "                                        location    salary  \\\n",
       "0                                     Austin, TX  150000.0   \n",
       "1                                     Austin, TX   90000.0   \n",
       "2                                     Austin, TX   57500.0   \n",
       "3                                     Austin, TX  135000.0   \n",
       "4                                     Austin, TX   70000.0   \n",
       "5    Denver, CO 80204 (Central West Denver area)   69673.0   \n",
       "6                                     Denver, CO  105000.0   \n",
       "7                                     Denver, CO   42500.0   \n",
       "8                               Denver, CO 80226   35000.0   \n",
       "9                                     Denver, CO  111000.0   \n",
       "10                                  Superior, CO  112500.0   \n",
       "11                                    Aurora, CO   40000.0   \n",
       "12                                    Denver, CO   63339.0   \n",
       "13                                   Boulder, CO  107500.0   \n",
       "14   Denver, CO 80204 (Central West Denver area)   88091.0   \n",
       "15                                    Denver, CO   85000.0   \n",
       "16                                   Boulder, CO   50500.0   \n",
       "17                                   Seattle, WA  125000.0   \n",
       "18                                   Seattle, WA  118000.0   \n",
       "19                                   Seattle, WA  140000.0   \n",
       "20                                   Seattle, WA  160000.0   \n",
       "21            Bellevue, WA 98004 (Downtown area)   35000.0   \n",
       "22                                   Seattle, WA  125000.0   \n",
       "23                                  Bellevue, WA   55548.0   \n",
       "24                                   Seattle, WA   95000.0   \n",
       "25                                   Seattle, WA  162500.0   \n",
       "26                                   Seattle, WA   57500.0   \n",
       "27                               Los Angeles, CA   65000.0   \n",
       "28                               Los Angeles, CA  180000.0   \n",
       "29                               Los Angeles, CA  103000.0   \n",
       "..                                           ...       ...   \n",
       "117                               Orangeburg, NY   25000.0   \n",
       "118                                 New York, NY  115000.0   \n",
       "119                                 New York, NY  110000.0   \n",
       "120                                  Atlanta, GA  101553.5   \n",
       "121                               Alpharetta, GA   82500.0   \n",
       "122                                  Atlanta, GA   85399.0   \n",
       "123     Atlanta, GA 30308 (Old Fourth Ward area)   80000.0   \n",
       "124                                  Atlanta, GA  112500.0   \n",
       "125                                  Atlanta, GA   85500.0   \n",
       "126                                  Atlanta, GA  177500.0   \n",
       "127                                  Atlanta, GA   87500.0   \n",
       "128                                  Atlanta, GA   69900.0   \n",
       "129                                  Atlanta, GA   80000.0   \n",
       "130                                  Atlanta, GA   24000.0   \n",
       "131                                  Atlanta, GA   66700.0   \n",
       "132                                  Atlanta, GA  107500.0   \n",
       "133                            San Francisco, CA  170000.0   \n",
       "134                            San Francisco, CA  135000.0   \n",
       "135                            San Francisco, CA  150000.0   \n",
       "136                                  Oakland, CA   96947.0   \n",
       "137                            San Francisco, CA  140000.0   \n",
       "138                             Redwood City, CA  170000.0   \n",
       "139                            San Francisco, CA  185000.0   \n",
       "140                            San Francisco, CA  150000.0   \n",
       "141                            San Francisco, CA  160000.0   \n",
       "142                            San Francisco, CA  111774.0   \n",
       "143                                 Berkeley, CA  155000.0   \n",
       "144                                San Diego, CA   68200.0   \n",
       "145                                San Diego, CA   53000.0   \n",
       "146                                San Diego, CA  100000.0   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Machine Learning Data Scientist. Forecasting, ...   \n",
       "1    XOR is leading a data revolution by giving tra...   \n",
       "2    Growing international custom research supplier...   \n",
       "3    Data mining competition experience preferred (...   \n",
       "4    Join our Medical Laboratory Scientists Groups:...   \n",
       "5    Clean data for analysis. Develop data collecti...   \n",
       "6    Data Scientist, and a UI Developer. Great atti...   \n",
       "7    Enter data from legal sources into database. I...   \n",
       "8    Looking for a Food Scientist:. Secondary and/o...   \n",
       "9    Validate data models (logical and physical) fo...   \n",
       "10   Gunther Douglas’ client is seeking a Data Scie...   \n",
       "11   Works with large complex data sets, including ...   \n",
       "12   Fulfill internal data requests, and coordinate...   \n",
       "13   Of visiting scientists; In use of excel, data ...   \n",
       "14   Budget development, processing and monitoring ...   \n",
       "15   Extensive knowledge and experience analyzing s...   \n",
       "16   Experience finding data and/or providing suppo...   \n",
       "17   Exposure to big data systems (Hadoop, HBASE, H...   \n",
       "18   We are searching for a highly motivated data s...   \n",
       "19   Data and image analysis using advanced statist...   \n",
       "20   Build big data, machine learning applications ...   \n",
       "21   Capture and record data in G2’s proprietary so...   \n",
       "22   Business Intelligence Scientist. SQL, Digital ...   \n",
       "23   Performing field surveys or studies, 2) respon...   \n",
       "24   Join our Medical Laboratory Scientists Groups:...   \n",
       "25   Working with a team of Analysts, Software Deve...   \n",
       "26   Growing international custom research supplier...   \n",
       "27   Partner with data scientists in the Technology...   \n",
       "28   Our data team consists of two data analysts an...   \n",
       "29   We are now bringing this same groundbreaking a...   \n",
       "..                                                 ...   \n",
       "117  Additional experience in statistical analysis ...   \n",
       "118  Any other experience within data scalability, ...   \n",
       "119  You will join the data engineering team and wo...   \n",
       "120  Assess data for completeness, accuracy, and qu...   \n",
       "121  Junior Data Scientist sought by Fortune 500 co...   \n",
       "122  As Behavioral Scientist you will:. Identify an...   \n",
       "123  We are looking for a bright and experienced da...   \n",
       "124  Python, data mining, data science; The data Sc...   \n",
       "125  Staff Scientists will have leadership responsi...   \n",
       "126  The client is looking for talented individuals...   \n",
       "127  -Post degree business based experience doing d...   \n",
       "128  The Medical Image Analysis Scientist, works wi...   \n",
       "129  Duties will include data conversion from multi...   \n",
       "130  Under broad supervision, assists technicians a...   \n",
       "131  Responsible for post award processing of grant...   \n",
       "132  Data Scientist, Supply Chain sought by Fortune...   \n",
       "133  Data migration, transformation, and scripting....   \n",
       "134  Machine Learning Senior Data Scientist. Mentor...   \n",
       "135  Established retail and eCommerce company in do...   \n",
       "136  In this position, you will serve as a Physical...   \n",
       "137  Big Data Stack:. Hadoop data Ingestion, data q...   \n",
       "138  Through the Our Clients pivotal world-view in ...   \n",
       "139  You will lead a team of 4 data scientists incl...   \n",
       "140  Data Mining Experience. The Data Engineers wor...   \n",
       "141  Position - Data Scientist - Recommendation Eng...   \n",
       "142  Under administrative direction of the Director...   \n",
       "143  The Machine Learning Operations group within t...   \n",
       "144  Proven experience with Business Intelligence t...   \n",
       "145  The candidates working in a Team culture, are ...   \n",
       "146  Experience working with large amounts of data....   \n",
       "\n",
       "                                                 title           city state  \n",
       "0               Senior Machine Learning Data Scientist         Austin    TX  \n",
       "1                   Senior Software Engineer/Team Lead         Austin    TX  \n",
       "2                                     Research Analyst         Austin    TX  \n",
       "3                            Machine Learning Engineer         Austin    TX  \n",
       "4                            LCMS Certifying Scientist         Austin    TX  \n",
       "5    SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...         Denver    CO  \n",
       "6             Big Data Developer (Spark, Hadoop, Hive)         Denver    CO  \n",
       "7                               Legal Research Analyst         Denver    CO  \n",
       "8             Food Scientist: Chemistry & Formulations         Denver    CO  \n",
       "9                      Government Enterprise Architect         Denver    CO  \n",
       "10                                      Data Scientist       Superior    CO  \n",
       "11                                    Research Analyst         Aurora    CO  \n",
       "12                            RESEARCH ANALYST – 16996         Denver    CO  \n",
       "13                        Managing Director for STROBE        Boulder    CO  \n",
       "14                           Business Manager - RADARS         Denver    CO  \n",
       "15       Global Marketing Manager - Food Manufacturing         Denver    CO  \n",
       "16                   Health & Human Sciences Librarian        Boulder    CO  \n",
       "17                    Data Scientist-Software Engineer        Seattle    WA  \n",
       "18                    Assistant Director, Data Science        Seattle    WA  \n",
       "19   Sr. Data Scientist / Machine Learning (In-vitr...        Seattle    WA  \n",
       "20     Machine Learning Engineer - Big Data, Python, R        Seattle    WA  \n",
       "21                  Research and Investigation Analyst       Bellevue    WA  \n",
       "22                     Business Intelligence Scientist        Seattle    WA  \n",
       "23              TMDL Lead (Environmental Specialist 4)       Bellevue    WA  \n",
       "24                          Variant Scientist (Remote)        Seattle    WA  \n",
       "25                           Sr. Global Device Manager        Seattle    WA  \n",
       "26                                    Research Analyst        Seattle    WA  \n",
       "27                 Social Media Marketing Data Analyst    Los Angeles    CA  \n",
       "28                               Senior Data Scientist    Los Angeles    CA  \n",
       "29         Senior Data Science Engineer and Instructor    Los Angeles    CA  \n",
       "..                                                 ...            ...   ...  \n",
       "117  Post-Doctoral Scientist (Analytical Psychophar...     Orangeburg    NY  \n",
       "118                                     Data Scientist       New York    NY  \n",
       "119                                  Big Data Engineer       New York    NY  \n",
       "120                              Statistician (Health)        Atlanta    GA  \n",
       "121                              Junior Data Scientist     Alpharetta    GA  \n",
       "122                               Behavioral Scientist        Atlanta    GA  \n",
       "123                                Lead Data Scientist        Atlanta    GA  \n",
       "124                              Senior Data Scientist        Atlanta    GA  \n",
       "125                    Staff Scientist (Goldsmith Lab)        Atlanta    GA  \n",
       "126                          Lead Quantitative Analyst        Atlanta    GA  \n",
       "127                             Marketing Statistician        Atlanta    GA  \n",
       "128                       Scientist, Med Imag Analysis        Atlanta    GA  \n",
       "129        Audit Snr (Banking) - Data Analysis 60K-80K        Atlanta    GA  \n",
       "130                                  Laboratory Aide 3        Atlanta    GA  \n",
       "131               Sponsored Research Financial Analyst        Atlanta    GA  \n",
       "132                      Data Scientist - Supply Chain        Atlanta    GA  \n",
       "133                        Data Engineer and Scientist  San Francisco    CA  \n",
       "134                Sr. Machine Learning Data Scientist  San Francisco    CA  \n",
       "135               Senior Data Scientist (Optimization)  San Francisco    CA  \n",
       "136                                 Physical Scientist        Oakland    CA  \n",
       "137                          Big Data Talend Developer  San Francisco    CA  \n",
       "138  Senior Data Scientist - Security Experience is...   Redwood City    CA  \n",
       "139                        Senior Data Science Manager  San Francisco    CA  \n",
       "140                             Data Engineer (Python)  San Francisco    CA  \n",
       "141             Data Scientist - Recommendation Engine  San Francisco    CA  \n",
       "142                   Manager I - Chief Microbiologist  San Francisco    CA  \n",
       "143  Lead Data Analyst (Machine Learning Operations...       Berkeley    CA  \n",
       "144           Strategic Research Opportunities Analyst      San Diego    CA  \n",
       "145                                          Scientist      San Diego    CA  \n",
       "146            Software Engineer (C#/Machine Learning)      San Diego    CA  \n",
       "\n",
       "[147 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c3ed6de7-8fe0-4cf4-abbd-abb2a188e05b"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "073e3f3e-21bc-4ab7-ae2e-272be0a409cc"
   },
   "outputs": [],
   "source": [
    "# calculate median and create feature with 1 as high salary\n",
    "\n",
    "median_data = df_2['salary'].median()\n",
    "median_data\n",
    "df_2['High_Low'] = df_2['salary'].map(lambda x: 1 if x >= median_data else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3c7ec3d2-87a0-4290-9d83-a6f4a9ae7e9c"
   },
   "source": [
    "### Q: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "987666b2-d8e6-4715-b499-c9d314fb70ce"
   },
   "source": [
    "It is 50% if we guess randomly, half the salaries will be below the median and half will be above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ea7e00cb-9956-44ec-b585-7b95f4d6284c"
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ce9161b3-eff3-475c-a087-a2be38d7f626"
   },
   "outputs": [],
   "source": [
    "# create statsmodel and summary\n",
    "import statsmodels.formula.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660487\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>High_Low</td>     <th>  No. Observations:  </th>  <td>   147</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   139</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 21 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.04556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:25:13</td>     <th>  Log-Likelihood:    </th> <td> -97.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -101.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.2339</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -0.1001</td> <td>    0.317</td> <td>   -0.316</td> <td> 0.752</td> <td>   -0.721     0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.CO]</th> <td>   -0.5931</td> <td>    0.689</td> <td>   -0.860</td> <td> 0.390</td> <td>   -1.944     0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.GA]</th> <td>   -0.7108</td> <td>    0.679</td> <td>   -1.047</td> <td> 0.295</td> <td>   -2.042     0.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.MA]</th> <td>    0.5521</td> <td>    0.578</td> <td>    0.955</td> <td> 0.339</td> <td>   -0.581     1.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.NJ]</th> <td>   -0.5931</td> <td>    1.265</td> <td>   -0.469</td> <td> 0.639</td> <td>   -3.072     1.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.NY]</th> <td>    0.7287</td> <td>    0.443</td> <td>    1.646</td> <td> 0.100</td> <td>   -0.139     1.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.TX]</th> <td>   -0.3054</td> <td>    0.966</td> <td>   -0.316</td> <td> 0.752</td> <td>   -2.199     1.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.WA]</th> <td>    0.5055</td> <td>    0.719</td> <td>    0.703</td> <td> 0.482</td> <td>   -0.904     1.915</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               High_Low   No. Observations:                  147\n",
       "Model:                          Logit   Df Residuals:                      139\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Mon, 21 Nov 2016   Pseudo R-squ.:                 0.04556\n",
       "Time:                        16:25:13   Log-Likelihood:                -97.092\n",
       "converged:                       True   LL-Null:                       -101.73\n",
       "                                        LLR p-value:                    0.2339\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -0.1001      0.317     -0.316      0.752        -0.721     0.520\n",
       "state[T.CO]    -0.5931      0.689     -0.860      0.390        -1.944     0.758\n",
       "state[T.GA]    -0.7108      0.679     -1.047      0.295        -2.042     0.620\n",
       "state[T.MA]     0.5521      0.578      0.955      0.339        -0.581     1.685\n",
       "state[T.NJ]    -0.5931      1.265     -0.469      0.639        -3.072     1.886\n",
       "state[T.NY]     0.7287      0.443      1.646      0.100        -0.139     1.597\n",
       "state[T.TX]    -0.3054      0.966     -0.316      0.752        -2.199     1.588\n",
       "state[T.WA]     0.5055      0.719      0.703      0.482        -0.904     1.915\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.logit(\"High_Low ~ state\", data=df_2).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficents here are showing a negative relationship(less income) in the states whose coef has a (-) in front and thus a 1 unit increase in the state leads to less of a chance of it being a high paying job.  The states such as NY, WA and MA are associated with a higher probability of finding a more lucrative job. \n",
    "\n",
    "One question i have is, why has the CA data been omitted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1ecd7811-d200-44bc-942f-4beb76d2689c"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' or 'Manager' is in the title \n",
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b847f46e-1626-4340-86fb-08dea8c31a84",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create senior, director, and manager dummies\n",
    "df_2['is_senior'] = df_2['title'].str.contains('Senior','Sr.').astype(int) # example\n",
    "df_2['is_Manager'] = df_2['title'].str.contains('Manager').astype(int)\n",
    "df_2['director'] = df_2['title'].str.contains('Director').astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142\n",
       "1      5\n",
       "Name: director, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.director.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.597094\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>High_Low</td>     <th>  No. Observations:  </th>  <td>   147</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   137</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     9</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 21 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.1372</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>19:35:47</td>     <th>  Log-Likelihood:    </th> <td> -87.773</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -101.73</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>0.0009890</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -0.5078</td> <td>    0.359</td> <td>   -1.416</td> <td> 0.157</td> <td>   -1.211     0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.CO]</th> <td>   -0.2478</td> <td>    0.709</td> <td>   -0.349</td> <td> 0.727</td> <td>   -1.637     1.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.GA]</th> <td>   -0.5205</td> <td>    0.729</td> <td>   -0.714</td> <td> 0.475</td> <td>   -1.949     0.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.MA]</th> <td>    0.7843</td> <td>    0.613</td> <td>    1.280</td> <td> 0.201</td> <td>   -0.417     1.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.NJ]</th> <td>   -0.1853</td> <td>    1.276</td> <td>   -0.145</td> <td> 0.885</td> <td>   -2.687     2.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.NY]</th> <td>    0.7262</td> <td>    0.480</td> <td>    1.513</td> <td> 0.130</td> <td>   -0.214     1.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.TX]</th> <td>   -1.0880</td> <td>    1.220</td> <td>   -0.892</td> <td> 0.373</td> <td>   -3.479     1.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.WA]</th> <td>    0.8788</td> <td>    0.735</td> <td>    1.195</td> <td> 0.232</td> <td>   -0.562     2.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_Manager</th>  <td>    0.3585</td> <td>    0.742</td> <td>    0.483</td> <td> 0.629</td> <td>   -1.095     1.812</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_senior</th>   <td>    2.6792</td> <td>    0.821</td> <td>    3.263</td> <td> 0.001</td> <td>    1.070     4.288</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               High_Low   No. Observations:                  147\n",
       "Model:                          Logit   Df Residuals:                      137\n",
       "Method:                           MLE   Df Model:                            9\n",
       "Date:                Mon, 21 Nov 2016   Pseudo R-squ.:                  0.1372\n",
       "Time:                        19:35:47   Log-Likelihood:                -87.773\n",
       "converged:                       True   LL-Null:                       -101.73\n",
       "                                        LLR p-value:                 0.0009890\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -0.5078      0.359     -1.416      0.157        -1.211     0.195\n",
       "state[T.CO]    -0.2478      0.709     -0.349      0.727        -1.637     1.142\n",
       "state[T.GA]    -0.5205      0.729     -0.714      0.475        -1.949     0.908\n",
       "state[T.MA]     0.7843      0.613      1.280      0.201        -0.417     1.986\n",
       "state[T.NJ]    -0.1853      1.276     -0.145      0.885        -2.687     2.316\n",
       "state[T.NY]     0.7262      0.480      1.513      0.130        -0.214     1.667\n",
       "state[T.TX]    -1.0880      1.220     -0.892      0.373        -3.479     1.303\n",
       "state[T.WA]     0.8788      0.735      1.195      0.232        -0.562     2.320\n",
       "is_Manager      0.3585      0.742      0.483      0.629        -1.095     1.812\n",
       "is_senior       2.6792      0.821      3.263      0.001         1.070     4.288\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.logit(\"High_Low ~ is_Manager + is_senior + is_Manager + state\", data=df_2).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large increase in probability that the job is higher pay if it has senior in title. Its the biggest determining factor out of all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7ca5cfdd-958c-4199-aafa-3d3f6c5ba3c4"
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c75a97f1-f30c-48b3-97cb-eaf7d525c734"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.660487\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>High_Low</td>     <th>  No. Observations:  </th>  <td>   147</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   139</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 21 Nov 2016</td> <th>  Pseudo R-squ.:     </th>  <td>0.04556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>16:24:53</td>     <th>  Log-Likelihood:    </th> <td> -97.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -101.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td>0.2339</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>   -0.1001</td> <td>    0.317</td> <td>   -0.316</td> <td> 0.752</td> <td>   -0.721     0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.CO]</th> <td>   -0.5931</td> <td>    0.689</td> <td>   -0.860</td> <td> 0.390</td> <td>   -1.944     0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.GA]</th> <td>   -0.7108</td> <td>    0.679</td> <td>   -1.047</td> <td> 0.295</td> <td>   -2.042     0.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.MA]</th> <td>    0.5521</td> <td>    0.578</td> <td>    0.955</td> <td> 0.339</td> <td>   -0.581     1.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.NJ]</th> <td>   -0.5931</td> <td>    1.265</td> <td>   -0.469</td> <td> 0.639</td> <td>   -3.072     1.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.NY]</th> <td>    0.7287</td> <td>    0.443</td> <td>    1.646</td> <td> 0.100</td> <td>   -0.139     1.597</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.TX]</th> <td>   -0.3054</td> <td>    0.966</td> <td>   -0.316</td> <td> 0.752</td> <td>   -2.199     1.588</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>state[T.WA]</th> <td>    0.5055</td> <td>    0.719</td> <td>    0.703</td> <td> 0.482</td> <td>   -0.904     1.915</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               High_Low   No. Observations:                  147\n",
       "Model:                          Logit   Df Residuals:                      139\n",
       "Method:                           MLE   Df Model:                            7\n",
       "Date:                Mon, 21 Nov 2016   Pseudo R-squ.:                 0.04556\n",
       "Time:                        16:24:53   Log-Likelihood:                -97.092\n",
       "converged:                       True   LL-Null:                       -101.73\n",
       "                                        LLR p-value:                    0.2339\n",
       "===============================================================================\n",
       "                  coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "-------------------------------------------------------------------------------\n",
       "Intercept      -0.1001      0.317     -0.316      0.752        -0.721     0.520\n",
       "state[T.CO]    -0.5931      0.689     -0.860      0.390        -1.944     0.758\n",
       "state[T.GA]    -0.7108      0.679     -1.047      0.295        -2.042     0.620\n",
       "state[T.MA]     0.5521      0.578      0.955      0.339        -0.581     1.685\n",
       "state[T.NJ]    -0.5931      1.265     -0.469      0.639        -3.072     1.886\n",
       "state[T.NY]     0.7287      0.443      1.646      0.100        -0.139     1.597\n",
       "state[T.TX]    -0.3054      0.966     -0.316      0.752        -2.199     1.588\n",
       "state[T.WA]     0.5055      0.719      0.703      0.482        -0.904     1.915\n",
       "===============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale, (patsy optional), and fit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from patsy import dmatrix\n",
    "import patsy\n",
    "y, X = patsy.dmatrices('High_Low ~ state', data = df_2)\n",
    "logit = sm.Logit(y,X)\n",
    "result = logit.fit()\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "1e6c6902-2b4a-49f0-b4c7-935a26577d22"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dums = pd.get_dummies(df_2['state'], prefix= 'st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>is_senior</th>\n",
       "      <th>is_Manager</th>\n",
       "      <th>director</th>\n",
       "      <th>High_Low</th>\n",
       "      <th>st_CO</th>\n",
       "      <th>st_GA</th>\n",
       "      <th>st_MA</th>\n",
       "      <th>st_NJ</th>\n",
       "      <th>st_NY</th>\n",
       "      <th>st_TX</th>\n",
       "      <th>st_WA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Machine Learning Data Scientist. Forecasting, ...</td>\n",
       "      <td>Senior Machine Learning Data Scientist</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XOR Data Exchange</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>XOR is leading a data revolution by giving tra...</td>\n",
       "      <td>Senior Software Engineer/Team Lead</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Volt Workforce Solutions</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Data mining competition experience preferred (...</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>LCMS Certifying Scientist</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    company    location    salary  \\\n",
       "0          All-In Analytics  Austin, TX  150000.0   \n",
       "1         XOR Data Exchange  Austin, TX   90000.0   \n",
       "2     Smith Arnold Partners  Austin, TX   57500.0   \n",
       "3  Volt Workforce Solutions  Austin, TX  135000.0   \n",
       "4     Lighthouse Recruiting  Austin, TX   70000.0   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Machine Learning Data Scientist. Forecasting, ...   \n",
       "1  XOR is leading a data revolution by giving tra...   \n",
       "2  Growing international custom research supplier...   \n",
       "3  Data mining competition experience preferred (...   \n",
       "4  Join our Medical Laboratory Scientists Groups:...   \n",
       "\n",
       "                                    title    city state  is_senior  \\\n",
       "0  Senior Machine Learning Data Scientist  Austin    TX          1   \n",
       "1      Senior Software Engineer/Team Lead  Austin    TX          1   \n",
       "2                        Research Analyst  Austin    TX          0   \n",
       "3               Machine Learning Engineer  Austin    TX          0   \n",
       "4               LCMS Certifying Scientist  Austin    TX          0   \n",
       "\n",
       "   is_Manager  director  High_Low  st_CO  st_GA  st_MA  st_NJ  st_NY  st_TX  \\\n",
       "0           0         0         1    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "1           0         0         0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "2           0         0         0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "3           0         0         1    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "4           0         0         0    0.0    0.0    0.0    0.0    0.0    1.0   \n",
       "\n",
       "   st_WA  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_2.join(dums.ix[:, 'st_CO':])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('st_CO', 'st_GA', 'st_MA', 'st_NJ', 'st_NY', 'st_TX', 'st_WA')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-55015a927bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# features = df_2['state', 'is_senior']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'st_CO'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_GA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_MA'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_NJ'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_NY'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_TX'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_WA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'High_Low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('st_CO', 'st_GA', 'st_MA', 'st_NJ', 'st_NY', 'st_TX', 'st_WA')"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "# features = df_2['state', 'is_senior']\n",
    "states = []\n",
    "X = data['st_CO', 'st_GA', 'st_MA', 'st_NJ', 'st_NY', 'st_TX', 'st_WA']\n",
    "y = data['High_Low']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "3667427c-6534-4dcd-8770-f492b0e3a39e"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "estimator should a be an estimator implementing 'fit' method, <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x162582b90> was passed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-2c65cb24d7e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHigh_Low\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#for metric in ['accuracy', 'precision', 'recall', 'roc_auc']: # example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     \u001b[0;31m# We clone the estimator to make sure that all the folds are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/sklearn/metrics/scorer.pyc\u001b[0m in \u001b[0;36mcheck_scoring\u001b[0;34m(estimator, scoring, allow_none)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         raise TypeError(\"estimator should a be an estimator implementing \"\n\u001b[0;32m--> 236\u001b[0;31m                         \"'fit' method, %r was passed\" % estimator)\n\u001b[0m\u001b[1;32m    237\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhas_scoring\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: estimator should a be an estimator implementing 'fit' method, <statsmodels.discrete.discrete_model.BinaryResultsWrapper object at 0x162582b90> was passed"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "cval_scores = cross_val_score(result, df_2.state, df_2.High_Low, cv=5 )\n",
    "\n",
    "\n",
    "#for metric in ['accuracy', 'precision', 'recall', 'roc_auc']: # example\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4263b1c0-bfde-42bf-ab45-71c7cd798835"
   },
   "source": [
    "### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2e7d6a29-a515-468a-9953-9d73a0f81de0"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty = 'l1', C=1.0)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "32d908a3-89d2-474c-a7f0-199bfae6da7e"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : X.design_info.column_names, 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "82f16f60-6c8b-4376-b3ec-b8ec61a0cde7"
   },
   "source": [
    "#### Optional: Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients. Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary. Which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3f242a55-4518-4c95-ae90-6888c68077d3"
   },
   "source": [
    "# Bonus Section: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "757205dc-443d-4754-9d23-e591e0921c02"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform()\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "f44df3c1-cf82-4271-8660-fdd0052097b6"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : vectorizer.get_feature_names(), 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e182bbe4-2a72-4e75-a3e8-c117688cb8a6"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a15ef8ea-3130-4c08-a165-ac34d2a8d829"
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b8a13337-0cde-4117-a928-ffae14661453"
   },
   "outputs": [],
   "source": [
    "# retest L1 and L2 regularization\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "model = LogisticRegressionCV()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "936cd752-6b3f-450f-bfb6-1659c6e71539"
   },
   "source": [
    "Score: | /24\n",
    "------|-------\n",
    "Identify: Problem Statement and Hypothesis | \n",
    "Acquire: Import Data using BeautifulSoup| \n",
    "Parse: Clean and Organize Data| \n",
    "Model: Perform Logistic Regression| \n",
    "Evaluate: Logistic Regression Results\t|\n",
    "Present: Blog Report with Findings and Recommendations\t\t| \n",
    "Interactive Tableau visualizations | \n",
    "Regularization |\n",
    "Bonus: Countvectorizer  | "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
