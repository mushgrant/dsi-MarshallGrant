{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "cc166dbc-d723-4076-8dd8-a290d911dc9b"
=======
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
>>>>>>> origin/master
   },
   "source": [
    "# Project 4: Web Scraping Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "59b0deac-55d6-4908-8dee-ce68611486f0"
=======
    "id": "34681254-c802-462f-829d-8894d0772d08"
>>>>>>> origin/master
   },
   "source": [
    "In Project 4, we practice two major skills: collecting data via  web scraping and building a binary predictor with Logistic Regression.\n",
    "\n",
<<<<<<< HEAD
    "We will collect salary information on data science jobs in a variety of markets. Using location, title, and job summary, we'll predict the salary of the job. For job posting sites, this is extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), extrapolating expected salary can help guide negotiations.\n",
    "\n",
    "Normally, we can use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Q: Why would we want this to be a classification problem?\n",
    "- A: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Section one focuses on scraping Indeed.com; then we use listings with salary information to build a model and predict additional salaries."
=======
    "We will collect salary information on data science jobs in a variety of markets. Using location, title, and job summary, we'll predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use Logistic Regression.\n",
    "\n",
    "- Question: Why would we want this to be a classification problem?\n",
    "- Answer: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "1321e3c4-2105-428e-9b1b-6d958453ef1d"
=======
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
>>>>>>> origin/master
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
<<<<<<< HEAD
    "focus": false,
    "id": "9d959074-bf26-4000-b0da-11273e253776"
   },
   "source": [
    "Scrape job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries. First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract."
=======
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "d9f7b5d1-b227-4bda-a87b-1606b62fb60b"
=======
    "id": "9732c901-ae26-4160-8376-42e22dd327df"
>>>>>>> origin/master
   },
   "source": [
    "#### Setup a request (using `requests`) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "\n",
    "The URL here has many query parameters\n",
    "\n",
    "- `q` for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- `l` for a location \n",
    "- `start` for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "focus": false,
<<<<<<< HEAD
    "id": "911505d6-159f-4146-967d-a8482fe27e3d"
   },
   "outputs": [],
   "source": [
    "URL = 'http://www.indeed.com/'"
=======
    "id": "e915023e-6b0d-4982-af2a-b1e0355f4927"
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\""
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "focus": false,
<<<<<<< HEAD
    "id": "78446809-fa02-48df-b60f-cbeda175a498"
=======
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
>>>>>>> origin/master
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
<<<<<<< HEAD
    "collapsed": false,
    "focus": false,
    "id": "c8846f3e-42a5-4714-9784-fb5d6a28524b"
   },
   "outputs": [],
   "source": [
    "# read site in soup\n",
    "r = requests.get(URL)\n",
    "soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "# Append to the full set of results\n",
    "results = soup.findAll('div', { \"class\" : \"result\" })\n"
=======
    "collapsed": true,
    "focus": false,
    "id": "2c6752c4-7704-4c94-8bc0-6f13d2d0d570"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "963bb376-7746-43ce-98ec-ea4162f7ead6"
=======
    "id": "bb0b866a-26a7-45e9-8084-5a0f90eb4b3e"
>>>>>>> origin/master
   },
   "source": [
    "Let's look at one result more closely. A single `result` looks like\n",
    "\n",
    "```\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&amp;campaignid=serp-linkcompanyname&amp;fromjk=2480d203f7e97210&amp;jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```\n",
    "\n",
<<<<<<< HEAD
    "While this has some of the more verbose elements removed, we can see that there is some structure to the above:\n",
=======
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
>>>>>>> origin/master
    "- The salary is available in a `nobr` element inside of a `td` element with `class='snip`.\n",
    "- The title of a job is in a link with class set to `jobtitle` and a `data-tn-element=\"jobTitle`.  \n",
    "- The location is set in a `span` with `class='location'`. \n",
    "- The company is set in a `span` with `class='company'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "27b6ffb9-b42f-4298-b07a-10e3bab030cd"
=======
    "id": "f1eddb90-4ba8-483c-a229-77e93aa53119"
>>>>>>> origin/master
   },
   "source": [
    "### Write 4 functions to extract each item: location, company, job, and salary.\n",
    "\n",
    "example: \n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
<<<<<<< HEAD
    "- Make sure these functions are robust and can handle cases where the data/field may not be available\n",
    "- Test the functions on the results above"
=======
    "\n",
    "- **Make sure these functions are robust and can handle cases where the data/field may not be available.**\n",
    "    - Remember to check if a field is empty or `None` for attempting to call methods on it\n",
    "    - Remember to use `try/except` if you anticipate errors\n",
    "- **Test** the functions on the results above and simple examples"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "focus": false,
<<<<<<< HEAD
    "id": "f4b0755f-42e1-438f-89fc-131a60b781cd"
   },
   "outputs": [],
   "source": [
    "# get text\n",
    "def extract_text(el):\n",
    "    if el:\n",
    "        return el.text.strip()\n",
    "    else:\n",
    "        return ''\n",
    "        \n",
    "# company\n",
    "def get_company_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'company'}))\n",
    "\n",
    "# location\n",
    "def get_location_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'location'}))\n",
    "\n",
    "# summary\n",
    "def get_summary_from_result(result):\n",
    "    return extract_text(result.find('span', {'class' : 'summary'}))\n",
    "# title\n",
    "def get_title_from_result(result):\n",
    "    return extract_text(result.find('a', {'data-tn-element' : 'jobTitle'}))\n",
    "# get salary if exists\n",
    "def get_salary_from_result(result):\n",
    "    salary_table = result.find('td', {'class' : 'snip'})\n",
    "    if salary_table:\n",
    "        snip = salary_table.find('nobr')\n",
    "        if snip:\n",
    "            return snip.text.strip()   \n",
    "    return None"
=======
    "id": "a1af53c9-9090-494f-b82e-cadb60a54909"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "dc1d32a3-b13c-4919-8723-ce50dbc7660f"
=======
    "id": "34070e89-9521-4b45-90c8-57a6599aac68"
>>>>>>> origin/master
   },
   "source": [
    "Now, to scale up our scraping, we need to accumulate more results. We can do this by examining the URL above.\n",
    "\n",
    "- \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\"\n",
    "\n",
<<<<<<< HEAD
    "There are two query parameters here we can alter to collect more results: the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try different city). The second controls where in the results to start and gives 10 results (so we can keep incrementing this by 10 to move further within the list)."
=======
    "There are two query parameters here we can alter to collect more results, the `l=New+York` and the `start=10`. The first controls the location of the results (so we can try a different city). The second controls where in the results to start and gives 10 results (thus, we can keep incrementing by 10 to go further in the list)."
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "27584c3f-f552-40a2-842a-0681b1fd6265"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and start points. \n",
=======
    "id": "e8beed7c-3e42-40c0-810f-5f67f8f885a0"
   },
   "source": [
    "#### Complete the following code to collect results from multiple cities and starting points. \n",
>>>>>>> origin/master
    "- Enter your city below to add it to the search\n",
    "- Remember to convert your salary to U.S. Dollars to match the other cities if the currency is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "focus": false,
<<<<<<< HEAD
    "id": "20a34e35-a4db-44eb-8490-9903f8bcf406"
   },
   "outputs": [],
   "source": [
    "# specify city\n",
    "YOUR_CITY = ['Atlanta, GA', 'Los+Angeles, CA', 'Seattle, WA', \n",
    "             'New+York, NY', 'San+Diego, CA', 'San+Francisco, CA', 'Denver CO']"
=======
    "id": "a9aa87ec-3575-4a01-a986-eb684f2c47d0"
   },
   "outputs": [],
   "source": [
    "YOUR_CITY = ''"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b02e2931-4d5a-4e1e-9504-c6ccaaf84bed"
   },
   "outputs": [],
   "source": [
    "# create template URL and max number of results (pages) to pull\n",
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "\n",
    "# for loop to pull data with bs4\n",
    "for city in set(YOUR_CITY):\n",
    "    for start in range(0, 500, 10):\n",
    "        r = requests.get(url_template.format(city, start))\n",
    "        # Grab the results from the request (as above)\n",
    "        soup = BeautifulSoup(r.content, \"lxml\")\n",
    "        # Append to the full set of results\n",
    "        results += soup.findAll('div', { \"class\" : \"result\" })\n",
    "   "
=======
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "04b0f9af-540e-402f-8292-81748707c676"
   },
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 100 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "\n",
    "results = []\n",
    "\n",
    "for city in set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "    'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "    'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', YOUR_CITY]):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        # Append to the full set of results\n",
    "        pass"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "10eb5902-4727-4947-a167-2531aa12a427"
=======
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
>>>>>>> origin/master
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "d601ff2f-fbdf-4c4f-8bbe-10c4a3132cc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7325, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine data into dictionaries\n",
    "rows = []\n",
    "for result in results:\n",
    "    if result:\n",
    "        row = {'company':get_company_from_result(result),\n",
    "              'location':get_location_from_result(result),\n",
    "              'summary':get_summary_from_result(result),\n",
    "              'title':get_title_from_result(result),\n",
    "               'salary':get_salary_from_result(result)\n",
    "              }\n",
    "        rows.append(row)\n",
    "\n",
    "# create dataframe\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(rows)\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()\n",
    "df['salary'].count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace = True)\n",
    "df.shape\n",
    "df['salary'].count()"
=======
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "6e259594-1c52-436b-ab9e-527e071941c1"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "faac26dc-392a-4f90-a397-144a070702cb"
=======
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
>>>>>>> origin/master
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58ff72c5-eef2-4a86-93ac-22f84ed9b752"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     company                                 location salary  \\\n",
      "0         Riverside Research                          Buckley AFB, CO   None   \n",
      "1                    Pearson                           Centennial, CO   None   \n",
      "2                     CoBank                               Denver, CO   None   \n",
      "3  BBC Research & Consulting  Denver, CO 80209 (Washington Park area)   None   \n",
      "4                      Aetna                               Denver, CO   None   \n",
      "\n",
      "                                             summary  \\\n",
      "0  Experience with data science algorithms, commo...   \n",
      "1  Data structures, data representation, data cle...   \n",
      "2  We are seeking a self-motivated, highly-driven...   \n",
      "3  Expertise in data and statistical analysis. Da...   \n",
      "4  Participates in all aspects of business intell...   \n",
      "\n",
      "                                              title  \n",
      "0                                    Data Scientist  \n",
      "1  Senior Data/Research Scientist, Machine Learning  \n",
      "2                  Senior Quantitative Risk Analyst  \n",
      "3                                     Data Analysis  \n",
      "4                               Statistical Analyst  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "5        True\n",
       "6       False\n",
       "7        True\n",
       "8        True\n",
       "9        True\n",
       "10       True\n",
       "11       True\n",
       "12      False\n",
       "13       True\n",
       "14       True\n",
       "18       True\n",
       "19       True\n",
       "20       True\n",
       "21       True\n",
       "22      False\n",
       "23       True\n",
       "24       True\n",
       "26       True\n",
       "27       True\n",
       "150      True\n",
       "151      True\n",
       "152      True\n",
       "153      True\n",
       "154      True\n",
       "155      True\n",
       "        ...  \n",
       "7101     True\n",
       "7107     True\n",
       "7108     True\n",
       "7109     True\n",
       "7110    False\n",
       "7111     True\n",
       "7112     True\n",
       "7113     True\n",
       "7114     True\n",
       "7115     True\n",
       "7116     True\n",
       "7121     True\n",
       "7122     True\n",
       "7123     True\n",
       "7124     True\n",
       "7125     True\n",
       "7126     True\n",
       "7127     True\n",
       "7128     True\n",
       "7129     True\n",
       "7130     True\n",
       "7137     True\n",
       "7138     True\n",
       "7139     True\n",
       "7140     True\n",
       "7141     True\n",
       "7142     True\n",
       "7143     True\n",
       "7144     True\n",
       "7205     True\n",
       "Name: salary, dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to only the rows that have salary entries\n",
    "\n",
    "# Remove duplicates\n",
    "\n",
    "# Filter out salary entries referring to week, hour or month\n",
    "data = df[~(df.salary.astype('str').str.contains('hour'))] # example\n",
    "data = data[~(data.salary.astype('str').str.contains('week'))]\n",
    "data = data[~(data.salary.astype('str').str.contains('month'))]\n",
    "\n",
    "\n",
    "data.shape\n",
    "data['salary'].count()\n",
    "print data.head()\n",
    "data['salary'].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        company  \\\n",
      "6                         Gunther Douglas, Inc.   \n",
      "12                        Denver Public Schools   \n",
      "22                                Mountain Ltd.   \n",
      "310         tronc (formerly Tribune Publishing)   \n",
      "321                                          LT   \n",
      "323                                   Codesmith   \n",
      "459                      Geode Executive Search   \n",
      "461                      Scienaptic Systems Inc   \n",
      "474                                Wade & Wendy   \n",
      "753                                  Dashbot.io   \n",
      "2164                Community College of Aurora   \n",
      "2168                      Denver Public Schools   \n",
      "2178                          10Roof Technology   \n",
      "2185                        xentity corporation   \n",
      "2273                         Lauren Enterprises   \n",
      "2331                              Denver Health   \n",
      "2373                     University of Colorado   \n",
      "2417                     University of Colorado   \n",
      "2420                               Potatoes USA   \n",
      "2499                              Denver Health   \n",
      "2511                     University of Colorado   \n",
      "2896                       G2 Web Services, LLC   \n",
      "2927                     Philanthropy Northwest   \n",
      "2957                      Dynamic Staffing Inc.   \n",
      "3034                                  HERO.Jobs   \n",
      "3065                      Smith Arnold Partners   \n",
      "3108                           All-In Analytics   \n",
      "3139           Cutting Edge Medical Diagnostics   \n",
      "3231                        State of Washington   \n",
      "3330                      Lighthouse Recruiting   \n",
      "...                                         ...   \n",
      "5297                           Emory University   \n",
      "5307                       Synergy Search Group   \n",
      "5373        Georgia Department of Public Health   \n",
      "5518                           Emory University   \n",
      "5519                Interesse International Inc   \n",
      "5862                      Bayone Solutions Inc.   \n",
      "5867                         Nisum Technologies   \n",
      "5893        Federal Emergency Management Agency   \n",
      "5975                      Workbridge Associates   \n",
      "5987                      Workbridge Associates   \n",
      "6006                  Corporate Labs Technology   \n",
      "6028                      Workbridge Associates   \n",
      "6061                      Workbridge Associates   \n",
      "6104                         Jobspring Partners   \n",
      "6106                      Workbridge Associates   \n",
      "6108  San Francisco Department of Public Health   \n",
      "6134                      Workbridge Associates   \n",
      "6152                  Corporate Labs Technology   \n",
      "6167                                    Harnham   \n",
      "6168                      Workbridge Associates   \n",
      "6267                         Jobspring Partners   \n",
      "6311                      Workbridge Associates   \n",
      "6327                      Workbridge Associates   \n",
      "6346                           All-In Analytics   \n",
      "6377                                    Averity   \n",
      "6380                      Workbridge Associates   \n",
      "6497          University of California Berkeley   \n",
      "6613                               UC San Diego   \n",
      "6801                      IGE Therapeutics, Inc   \n",
      "7110                      Workbridge Associates   \n",
      "\n",
      "                                         location                      salary  \\\n",
      "6                                    Superior, CO   $95,000 - $130,000 a year   \n",
      "12    Denver, CO 80204 (Central West Denver area)    $63,339 - $76,007 a year   \n",
      "22                                     Denver, CO              $42,500 a year   \n",
      "310                               Los Angeles, CA    $60,000 - $70,000 a year   \n",
      "321                               Los Angeles, CA             $180,000 a year   \n",
      "323                               Los Angeles, CA             $103,000 a year   \n",
      "459                                  New York, NY             $200,000 a year   \n",
      "461                                  New York, NY             $100,000 a year   \n",
      "474                                  New York, NY   $80,000 - $120,000 a year   \n",
      "753                             San Francisco, CA  $160,000 - $180,000 a year   \n",
      "2164                                   Aurora, CO              $40,000 a year   \n",
      "2168                                   Denver, CO    $57,580 - $69,098 a year   \n",
      "2178                                   Denver, CO             $105,000 a year   \n",
      "2185                                   Denver, CO   $95,000 - $127,000 a year   \n",
      "2273                             Denver, CO 80226              $35,000 a year   \n",
      "2331  Denver, CO 80204 (Central West Denver area)              $88,091 a year   \n",
      "2373                                   Aurora, CO    $50,000 - $63,000 a year   \n",
      "2417                                  Boulder, CO  $100,000 - $115,000 a year   \n",
      "2420                                   Denver, CO              $85,000 a year   \n",
      "2499  Denver, CO 80204 (Central West Denver area)              $66,654 a year   \n",
      "2511                                  Boulder, CO              $50,500 a year   \n",
      "2896           Bellevue, WA 98004 (Downtown area)              $35,000 a year   \n",
      "2927            Seattle, WA 98121 (Belltown area)    $50,000 - $60,000 a year   \n",
      "2957                                  Seattle, WA             $125,000 a year   \n",
      "3034                                  Seattle, WA             $160,000 a year   \n",
      "3065                                  Seattle, WA    $50,000 - $65,000 a year   \n",
      "3108                                  Seattle, WA  $150,000 - $175,000 a year   \n",
      "3139                                  Seattle, WA             $140,000 a year   \n",
      "3231                                 Bellevue, WA    $48,060 - $63,036 a year   \n",
      "3330                                  Seattle, WA   $90,000 - $100,000 a year   \n",
      "...                                           ...                         ...   \n",
      "5297                                  Atlanta, GA              $69,900 a year   \n",
      "5307                                  Atlanta, GA              $80,000 a year   \n",
      "5373                                  Atlanta, GA              $24,000 a year   \n",
      "5518                                  Atlanta, GA              $66,700 a year   \n",
      "5519                                  Atlanta, GA    $60,000 - $70,000 a year   \n",
      "5862                            San Francisco, CA             $160,000 a year   \n",
      "5867                            San Francisco, CA             $140,000 a year   \n",
      "5893                                  Oakland, CA   $84,302 - $109,592 a year   \n",
      "5975                            San Francisco, CA  $130,000 - $160,000 a year   \n",
      "5987                            San Francisco, CA  $135,000 - $180,000 a year   \n",
      "6006                                 Brisbane, CA  $110,000 - $180,000 a year   \n",
      "6028                            San Francisco, CA  $135,000 - $165,000 a year   \n",
      "6061                            San Francisco, CA  $140,000 - $160,000 a year   \n",
      "6104                             Redwood City, CA  $150,000 - $170,000 a year   \n",
      "6106                            San Francisco, CA  $120,000 - $160,000 a year   \n",
      "6108                            San Francisco, CA   $98,202 - $125,346 a year   \n",
      "6134                            San Francisco, CA  $150,000 - $200,000 a year   \n",
      "6152                                 Brisbane, CA  $110,000 - $180,000 a year   \n",
      "6167                            San Francisco, CA             $185,000 a year   \n",
      "6168                            San Francisco, CA  $140,000 - $180,000 a year   \n",
      "6267                             Redwood City, CA  $150,000 - $180,000 a year   \n",
      "6311                            San Francisco, CA  $145,000 - $175,000 a year   \n",
      "6327                            San Francisco, CA  $140,000 - $160,000 a year   \n",
      "6346                            San Francisco, CA  $120,000 - $150,000 a year   \n",
      "6377                            San Francisco, CA  $180,000 - $230,000 a year   \n",
      "6380                            San Francisco, CA  $170,000 - $190,000 a year   \n",
      "6497                                 Berkeley, CA    $65,000 - $75,000 a year   \n",
      "6613                                San Diego, CA    $57,100 - $79,300 a year   \n",
      "6801                                San Diego, CA              $53,000 a year   \n",
      "7110                                San Diego, CA   $85,000 - $115,000 a year   \n",
      "\n",
      "                                                summary  \\\n",
      "6     Gunther Douglas’ client is seeking a Data Scie...   \n",
      "12    Clean data for analysis. Develop data collecti...   \n",
      "22    Enter data from legal sources into database. I...   \n",
      "310   Partner with data scientists in the Technology...   \n",
      "321   Our data team consists of two data analysts an...   \n",
      "323   We are now bringing this same groundbreaking a...   \n",
      "459   Data Scientist - Text Analytics - SQL, R, SAS*...   \n",
      "461   We are looking for an energetic and experience...   \n",
      "474   Our Data Scientist will integrate data from we...   \n",
      "753   Data migration, transformation, and scripting....   \n",
      "2164  Works with large complex data sets, including ...   \n",
      "2168  Fulfill internal data requests, and coordinate...   \n",
      "2178  Data Scientist, and a UI Developer. Great atti...   \n",
      "2185  Validate data models (logical and physical) fo...   \n",
      "2273  Looking for a Food Scientist:. Secondary and/o...   \n",
      "2331  Budget development, processing and monitoring ...   \n",
      "2373  Research information and data problems. Certif...   \n",
      "2417  Of visiting scientists; In use of excel, data ...   \n",
      "2420  Extensive knowledge and experience analyzing s...   \n",
      "2499  Typically, one (1) or more years of healthcare...   \n",
      "2511  Experience finding data and/or providing suppo...   \n",
      "2896  Capture and record data in G2’s proprietary so...   \n",
      "2927  Conduct research and provide data analysis in ...   \n",
      "2957  Exposure to big data systems (Hadoop, HBASE, H...   \n",
      "3034  Build big data, machine learning applications ...   \n",
      "3065  Growing international custom research supplier...   \n",
      "3108  Working with a team of Analysts, Software Deve...   \n",
      "3139  Data and image analysis using advanced statist...   \n",
      "3231  Performing field surveys or studies, 2) respon...   \n",
      "3330  Join our Medical Laboratory Scientists Groups:...   \n",
      "...                                                 ...   \n",
      "5297  The Medical Image Analysis Scientist, works wi...   \n",
      "5307  Duties will include data conversion from multi...   \n",
      "5373  Under broad supervision, assists technicians a...   \n",
      "5518  Responsible for post award processing of grant...   \n",
      "5519  Estimate numerical data; Must see through the ...   \n",
      "5862  Position - Data Scientist - Recommendation Eng...   \n",
      "5867  Big Data Stack:. Hadoop data Ingestion, data q...   \n",
      "5893  In this position, you will serve as a Physical...   \n",
      "5975  The Data Scientist will join a very senior tea...   \n",
      "5987  They are seeking a Data Scientist to join thei...   \n",
      "6006  Natural Language Processing Brisbane, CA Sign ...   \n",
      "6028  A leading San Francisco consumer web and perso...   \n",
      "6061  Established retail and eCommerce company in do...   \n",
      "6104  A fast growing company located in Redwood City...   \n",
      "6106  The Principal Data Scientist will be working o...   \n",
      "6108  Under administrative direction of the Director...   \n",
      "6134  This group works alongside the algorithms R&D ...   \n",
      "6152  Machine Learning Developer Brisbane, CA Sign o...   \n",
      "6167  You will lead a team of 4 data scientists incl...   \n",
      "6168  The Data Scientist will have an opportunity to...   \n",
      "6267  A fast growing company located in Redwood City...   \n",
      "6311  The Senior Data Engineer will be working along...   \n",
      "6327  Data Mining Experience. The Data Engineers wor...   \n",
      "6346  Machine Learning Senior Data Scientist. Mentor...   \n",
      "6377  Enabling our Data Scientists to create product...   \n",
      "6380  A San Francisco-based agriculture software com...   \n",
      "6497  Enforces EI’s confidential data access policy....   \n",
      "6613  Proven experience with Business Intelligence t...   \n",
      "6801  The candidates working in a Team culture, are ...   \n",
      "7110  Experience working with large amounts of data....   \n",
      "\n",
      "                                                  title  \n",
      "6                                        Data Scientist  \n",
      "12    SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...  \n",
      "22                               Legal Research Analyst  \n",
      "310                 Social Media Marketing Data Analyst  \n",
      "321                               Senior Data Scientist  \n",
      "323         Senior Data Science Engineer and Instructor  \n",
      "459       Data Scientist - Text Analytics - SQL, R, SAS  \n",
      "461                                      Data Scientist  \n",
      "474                Wade & Wendy_Data Scientist/Engineer  \n",
      "753                         Data Engineer and Scientist  \n",
      "2164                                   Research Analyst  \n",
      "2168                           RESEARCH ANALYST – 16996  \n",
      "2178           Big Data Developer (Spark, Hadoop, Hive)  \n",
      "2185                    Government Enterprise Architect  \n",
      "2273           Food Scientist: Chemistry & Formulations  \n",
      "2331                          Business Manager - RADARS  \n",
      "2373                                  Bioinformationist  \n",
      "2417                       Managing Director for STROBE  \n",
      "2420      Global Marketing Manager - Food Manufacturing  \n",
      "2499          RN-Statistical Research Specilist Nursing  \n",
      "2511                  Health & Human Sciences Librarian  \n",
      "2896                 Research and Investigation Analyst  \n",
      "2927              Research Analyst, The Giving Practice  \n",
      "2957                   Data Scientist-Software Engineer  \n",
      "3034    Machine Learning Engineer - Big Data, Python, R  \n",
      "3065                                   Research Analyst  \n",
      "3108                          Sr. Global Device Manager  \n",
      "3139  Sr. Data Scientist / Machine Learning (In-vitr...  \n",
      "3231             TMDL Lead (Environmental Specialist 4)  \n",
      "3330                         Variant Scientist (Remote)  \n",
      "...                                                 ...  \n",
      "5297                       Scientist, Med Imag Analysis  \n",
      "5307        Audit Snr (Banking) - Data Analysis 60K-80K  \n",
      "5373                                  Laboratory Aide 3  \n",
      "5518               Sponsored Research Financial Analyst  \n",
      "5519                    Market Research & Sales Analyst  \n",
      "5862             Data Scientist - Recommendation Engine  \n",
      "5867                          Big Data Talend Developer  \n",
      "5893                                 Physical Scientist  \n",
      "5975                  Data Scientist (Image Processing)  \n",
      "5987                                     Data Scientist  \n",
      "6006       Data Scientist (Natural Language Processing)  \n",
      "6028                 Data Scientist (Human Computation)  \n",
      "6061               Senior Data Scientist (Optimization)  \n",
      "6104                                     Data Scientist  \n",
      "6106          Principal Data Scientist (Recommendation)  \n",
      "6108                   Manager I - Chief Microbiologist  \n",
      "6134          Senior Data Engineer- Algorithms Platform  \n",
      "6152                  Data Scientist (Machine Learning)  \n",
      "6167                        Senior Data Science Manager  \n",
      "6168                              Senior Data Scientist  \n",
      "6267       Data Scientist- cool startup in RedWood City  \n",
      "6311     Senior Data Engineer - Recommendation Platform  \n",
      "6327                             Data Engineer (Python)  \n",
      "6346                Sr. Machine Learning Data Scientist  \n",
      "6377             Executive Director of Data Engineering  \n",
      "6380                           Principal Data Scientist  \n",
      "6497         Office Manager, Energy Institute at Haas ,  \n",
      "6613           Strategic Research Opportunities Analyst  \n",
      "6801                                          Scientist  \n",
      "7110            Software Engineer (C#/Machine Learning)  \n",
      "\n",
      "[146 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(146, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print new_data\n",
    "new_data.shape"
=======
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "58533e57-f86b-494a-b841-e7b59c6229c6"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "e1f58de9-78a7-49c1-b1ff-145a8f983790"
=======
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
>>>>>>> origin/master
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "f2eaea83-8f84-48d3-af17-037538d06601"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "def extract_salary_average(salary_string):\n",
    "    regex = r'\\$([0-9]+,[0-9]+)'\n",
    "    matches = re.findall(regex, salary_string)\n",
    "    return np.mean([float(salary.replace(',', '')) for salary in matches ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2d46d846-8aeb-49c3-86ac-768c4fc81552"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6c90cae808d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use '.map' to transform salary to new feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_salary_average\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   2102\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2104\u001b[0;31m             \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2106\u001b[0m         return self._constructor(new_values,\n",
      "\u001b[0;32mpandas/src/inference.pyx\u001b[0m in \u001b[0;36mpandas.lib.map_infer (pandas/lib.c:62658)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-a76c7d5c6ada>\u001b[0m in \u001b[0;36mextract_salary_average\u001b[0;34m(salary_string)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_salary_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalary_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mregex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'\\$([0-9]+,[0-9]+)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msalary_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msalary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msalary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexversion\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x02020000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or buffer"
     ]
    }
   ],
   "source": [
    "# use '.map' to transform salary to new feature\n",
    "new_data['salary'] = new_data['salary'].map(extract_salary_average)"
=======
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        company  \\\n",
      "6                         Gunther Douglas, Inc.   \n",
      "12                        Denver Public Schools   \n",
      "22                                Mountain Ltd.   \n",
      "310         tronc (formerly Tribune Publishing)   \n",
      "321                                          LT   \n",
      "323                                   Codesmith   \n",
      "459                      Geode Executive Search   \n",
      "461                      Scienaptic Systems Inc   \n",
      "474                                Wade & Wendy   \n",
      "753                                  Dashbot.io   \n",
      "2164                Community College of Aurora   \n",
      "2168                      Denver Public Schools   \n",
      "2178                          10Roof Technology   \n",
      "2185                        xentity corporation   \n",
      "2273                         Lauren Enterprises   \n",
      "2331                              Denver Health   \n",
      "2373                     University of Colorado   \n",
      "2417                     University of Colorado   \n",
      "2420                               Potatoes USA   \n",
      "2499                              Denver Health   \n",
      "2511                     University of Colorado   \n",
      "2896                       G2 Web Services, LLC   \n",
      "2927                     Philanthropy Northwest   \n",
      "2957                      Dynamic Staffing Inc.   \n",
      "3034                                  HERO.Jobs   \n",
      "3065                      Smith Arnold Partners   \n",
      "3108                           All-In Analytics   \n",
      "3139           Cutting Edge Medical Diagnostics   \n",
      "3231                        State of Washington   \n",
      "3330                      Lighthouse Recruiting   \n",
      "...                                         ...   \n",
      "5297                           Emory University   \n",
      "5307                       Synergy Search Group   \n",
      "5373        Georgia Department of Public Health   \n",
      "5518                           Emory University   \n",
      "5519                Interesse International Inc   \n",
      "5862                      Bayone Solutions Inc.   \n",
      "5867                         Nisum Technologies   \n",
      "5893        Federal Emergency Management Agency   \n",
      "5975                      Workbridge Associates   \n",
      "5987                      Workbridge Associates   \n",
      "6006                  Corporate Labs Technology   \n",
      "6028                      Workbridge Associates   \n",
      "6061                      Workbridge Associates   \n",
      "6104                         Jobspring Partners   \n",
      "6106                      Workbridge Associates   \n",
      "6108  San Francisco Department of Public Health   \n",
      "6134                      Workbridge Associates   \n",
      "6152                  Corporate Labs Technology   \n",
      "6167                                    Harnham   \n",
      "6168                      Workbridge Associates   \n",
      "6267                         Jobspring Partners   \n",
      "6311                      Workbridge Associates   \n",
      "6327                      Workbridge Associates   \n",
      "6346                           All-In Analytics   \n",
      "6377                                    Averity   \n",
      "6380                      Workbridge Associates   \n",
      "6497          University of California Berkeley   \n",
      "6613                               UC San Diego   \n",
      "6801                      IGE Therapeutics, Inc   \n",
      "7110                      Workbridge Associates   \n",
      "\n",
      "                                         location    salary  \\\n",
      "6                                    Superior, CO  112500.0   \n",
      "12    Denver, CO 80204 (Central West Denver area)   69673.0   \n",
      "22                                     Denver, CO   42500.0   \n",
      "310                               Los Angeles, CA   65000.0   \n",
      "321                               Los Angeles, CA  180000.0   \n",
      "323                               Los Angeles, CA  103000.0   \n",
      "459                                  New York, NY  200000.0   \n",
      "461                                  New York, NY  100000.0   \n",
      "474                                  New York, NY  100000.0   \n",
      "753                             San Francisco, CA  170000.0   \n",
      "2164                                   Aurora, CO   40000.0   \n",
      "2168                                   Denver, CO   63339.0   \n",
      "2178                                   Denver, CO  105000.0   \n",
      "2185                                   Denver, CO  111000.0   \n",
      "2273                             Denver, CO 80226   35000.0   \n",
      "2331  Denver, CO 80204 (Central West Denver area)   88091.0   \n",
      "2373                                   Aurora, CO   56500.0   \n",
      "2417                                  Boulder, CO  107500.0   \n",
      "2420                                   Denver, CO   85000.0   \n",
      "2499  Denver, CO 80204 (Central West Denver area)   66654.0   \n",
      "2511                                  Boulder, CO   50500.0   \n",
      "2896           Bellevue, WA 98004 (Downtown area)   35000.0   \n",
      "2927            Seattle, WA 98121 (Belltown area)   55000.0   \n",
      "2957                                  Seattle, WA  125000.0   \n",
      "3034                                  Seattle, WA  160000.0   \n",
      "3065                                  Seattle, WA   57500.0   \n",
      "3108                                  Seattle, WA  162500.0   \n",
      "3139                                  Seattle, WA  140000.0   \n",
      "3231                                 Bellevue, WA   55548.0   \n",
      "3330                                  Seattle, WA   95000.0   \n",
      "...                                           ...       ...   \n",
      "5297                                  Atlanta, GA   69900.0   \n",
      "5307                                  Atlanta, GA   80000.0   \n",
      "5373                                  Atlanta, GA   24000.0   \n",
      "5518                                  Atlanta, GA   66700.0   \n",
      "5519                                  Atlanta, GA   65000.0   \n",
      "5862                            San Francisco, CA  160000.0   \n",
      "5867                            San Francisco, CA  140000.0   \n",
      "5893                                  Oakland, CA   96947.0   \n",
      "5975                            San Francisco, CA  145000.0   \n",
      "5987                            San Francisco, CA  157500.0   \n",
      "6006                                 Brisbane, CA  145000.0   \n",
      "6028                            San Francisco, CA  150000.0   \n",
      "6061                            San Francisco, CA  150000.0   \n",
      "6104                             Redwood City, CA  160000.0   \n",
      "6106                            San Francisco, CA  140000.0   \n",
      "6108                            San Francisco, CA  111774.0   \n",
      "6134                            San Francisco, CA  175000.0   \n",
      "6152                                 Brisbane, CA  145000.0   \n",
      "6167                            San Francisco, CA  185000.0   \n",
      "6168                            San Francisco, CA  160000.0   \n",
      "6267                             Redwood City, CA  165000.0   \n",
      "6311                            San Francisco, CA  160000.0   \n",
      "6327                            San Francisco, CA  150000.0   \n",
      "6346                            San Francisco, CA  135000.0   \n",
      "6377                            San Francisco, CA  205000.0   \n",
      "6380                            San Francisco, CA  180000.0   \n",
      "6497                                 Berkeley, CA   70000.0   \n",
      "6613                                San Diego, CA   68200.0   \n",
      "6801                                San Diego, CA   53000.0   \n",
      "7110                                San Diego, CA  100000.0   \n",
      "\n",
      "                                                summary  \\\n",
      "6     Gunther Douglas’ client is seeking a Data Scie...   \n",
      "12    Clean data for analysis. Develop data collecti...   \n",
      "22    Enter data from legal sources into database. I...   \n",
      "310   Partner with data scientists in the Technology...   \n",
      "321   Our data team consists of two data analysts an...   \n",
      "323   We are now bringing this same groundbreaking a...   \n",
      "459   Data Scientist - Text Analytics - SQL, R, SAS*...   \n",
      "461   We are looking for an energetic and experience...   \n",
      "474   Our Data Scientist will integrate data from we...   \n",
      "753   Data migration, transformation, and scripting....   \n",
      "2164  Works with large complex data sets, including ...   \n",
      "2168  Fulfill internal data requests, and coordinate...   \n",
      "2178  Data Scientist, and a UI Developer. Great atti...   \n",
      "2185  Validate data models (logical and physical) fo...   \n",
      "2273  Looking for a Food Scientist:. Secondary and/o...   \n",
      "2331  Budget development, processing and monitoring ...   \n",
      "2373  Research information and data problems. Certif...   \n",
      "2417  Of visiting scientists; In use of excel, data ...   \n",
      "2420  Extensive knowledge and experience analyzing s...   \n",
      "2499  Typically, one (1) or more years of healthcare...   \n",
      "2511  Experience finding data and/or providing suppo...   \n",
      "2896  Capture and record data in G2’s proprietary so...   \n",
      "2927  Conduct research and provide data analysis in ...   \n",
      "2957  Exposure to big data systems (Hadoop, HBASE, H...   \n",
      "3034  Build big data, machine learning applications ...   \n",
      "3065  Growing international custom research supplier...   \n",
      "3108  Working with a team of Analysts, Software Deve...   \n",
      "3139  Data and image analysis using advanced statist...   \n",
      "3231  Performing field surveys or studies, 2) respon...   \n",
      "3330  Join our Medical Laboratory Scientists Groups:...   \n",
      "...                                                 ...   \n",
      "5297  The Medical Image Analysis Scientist, works wi...   \n",
      "5307  Duties will include data conversion from multi...   \n",
      "5373  Under broad supervision, assists technicians a...   \n",
      "5518  Responsible for post award processing of grant...   \n",
      "5519  Estimate numerical data; Must see through the ...   \n",
      "5862  Position - Data Scientist - Recommendation Eng...   \n",
      "5867  Big Data Stack:. Hadoop data Ingestion, data q...   \n",
      "5893  In this position, you will serve as a Physical...   \n",
      "5975  The Data Scientist will join a very senior tea...   \n",
      "5987  They are seeking a Data Scientist to join thei...   \n",
      "6006  Natural Language Processing Brisbane, CA Sign ...   \n",
      "6028  A leading San Francisco consumer web and perso...   \n",
      "6061  Established retail and eCommerce company in do...   \n",
      "6104  A fast growing company located in Redwood City...   \n",
      "6106  The Principal Data Scientist will be working o...   \n",
      "6108  Under administrative direction of the Director...   \n",
      "6134  This group works alongside the algorithms R&D ...   \n",
      "6152  Machine Learning Developer Brisbane, CA Sign o...   \n",
      "6167  You will lead a team of 4 data scientists incl...   \n",
      "6168  The Data Scientist will have an opportunity to...   \n",
      "6267  A fast growing company located in Redwood City...   \n",
      "6311  The Senior Data Engineer will be working along...   \n",
      "6327  Data Mining Experience. The Data Engineers wor...   \n",
      "6346  Machine Learning Senior Data Scientist. Mentor...   \n",
      "6377  Enabling our Data Scientists to create product...   \n",
      "6380  A San Francisco-based agriculture software com...   \n",
      "6497  Enforces EI’s confidential data access policy....   \n",
      "6613  Proven experience with Business Intelligence t...   \n",
      "6801  The candidates working in a Team culture, are ...   \n",
      "7110  Experience working with large amounts of data....   \n",
      "\n",
      "                                                  title  \n",
      "6                                        Data Scientist  \n",
      "12    SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...  \n",
      "22                               Legal Research Analyst  \n",
      "310                 Social Media Marketing Data Analyst  \n",
      "321                               Senior Data Scientist  \n",
      "323         Senior Data Science Engineer and Instructor  \n",
      "459       Data Scientist - Text Analytics - SQL, R, SAS  \n",
      "461                                      Data Scientist  \n",
      "474                Wade & Wendy_Data Scientist/Engineer  \n",
      "753                         Data Engineer and Scientist  \n",
      "2164                                   Research Analyst  \n",
      "2168                           RESEARCH ANALYST – 16996  \n",
      "2178           Big Data Developer (Spark, Hadoop, Hive)  \n",
      "2185                    Government Enterprise Architect  \n",
      "2273           Food Scientist: Chemistry & Formulations  \n",
      "2331                          Business Manager - RADARS  \n",
      "2373                                  Bioinformationist  \n",
      "2417                       Managing Director for STROBE  \n",
      "2420      Global Marketing Manager - Food Manufacturing  \n",
      "2499          RN-Statistical Research Specilist Nursing  \n",
      "2511                  Health & Human Sciences Librarian  \n",
      "2896                 Research and Investigation Analyst  \n",
      "2927              Research Analyst, The Giving Practice  \n",
      "2957                   Data Scientist-Software Engineer  \n",
      "3034    Machine Learning Engineer - Big Data, Python, R  \n",
      "3065                                   Research Analyst  \n",
      "3108                          Sr. Global Device Manager  \n",
      "3139  Sr. Data Scientist / Machine Learning (In-vitr...  \n",
      "3231             TMDL Lead (Environmental Specialist 4)  \n",
      "3330                         Variant Scientist (Remote)  \n",
      "...                                                 ...  \n",
      "5297                       Scientist, Med Imag Analysis  \n",
      "5307        Audit Snr (Banking) - Data Analysis 60K-80K  \n",
      "5373                                  Laboratory Aide 3  \n",
      "5518               Sponsored Research Financial Analyst  \n",
      "5519                    Market Research & Sales Analyst  \n",
      "5862             Data Scientist - Recommendation Engine  \n",
      "5867                          Big Data Talend Developer  \n",
      "5893                                 Physical Scientist  \n",
      "5975                  Data Scientist (Image Processing)  \n",
      "5987                                     Data Scientist  \n",
      "6006       Data Scientist (Natural Language Processing)  \n",
      "6028                 Data Scientist (Human Computation)  \n",
      "6061               Senior Data Scientist (Optimization)  \n",
      "6104                                     Data Scientist  \n",
      "6106          Principal Data Scientist (Recommendation)  \n",
      "6108                   Manager I - Chief Microbiologist  \n",
      "6134          Senior Data Engineer- Algorithms Platform  \n",
      "6152                  Data Scientist (Machine Learning)  \n",
      "6167                        Senior Data Science Manager  \n",
      "6168                              Senior Data Scientist  \n",
      "6267       Data Scientist- cool startup in RedWood City  \n",
      "6311     Senior Data Engineer - Recommendation Platform  \n",
      "6327                             Data Engineer (Python)  \n",
      "6346                Sr. Machine Learning Data Scientist  \n",
      "6377             Executive Director of Data Engineering  \n",
      "6380                           Principal Data Scientist  \n",
      "6497         Office Manager, Energy Institute at Haas ,  \n",
      "6613           Strategic Research Opportunities Analyst  \n",
      "6801                                          Scientist  \n",
      "7110            Software Engineer (C#/Machine Learning)  \n",
      "\n",
      "[146 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gunther Douglas, Inc.</td>\n",
       "      <td>Superior, CO</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Gunther Douglas’ client is seeking a Data Scie...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>69673.0</td>\n",
       "      <td>Clean data for analysis. Develop data collecti...</td>\n",
       "      <td>SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain Ltd.</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>Enter data from legal sources into database. I...</td>\n",
       "      <td>Legal Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tronc (formerly Tribune Publishing)</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Partner with data scientists in the Technology...</td>\n",
       "      <td>Social Media Marketing Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Our data team consists of two data analysts an...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codesmith</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>We are now bringing this same groundbreaking a...</td>\n",
       "      <td>Senior Data Science Engineer and Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Geode Executive Search</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Data Scientist - Text Analytics - SQL, R, SAS*...</td>\n",
       "      <td>Data Scientist - Text Analytics - SQL, R, SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scienaptic Systems Inc</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>We are looking for an energetic and experience...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wade &amp; Wendy</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Our Data Scientist will integrate data from we...</td>\n",
       "      <td>Wade &amp; Wendy_Data Scientist/Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dashbot.io</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Data migration, transformation, and scripting....</td>\n",
       "      <td>Data Engineer and Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Community College of Aurora</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Works with large complex data sets, including ...</td>\n",
       "      <td>Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>63339.0</td>\n",
       "      <td>Fulfill internal data requests, and coordinate...</td>\n",
       "      <td>RESEARCH ANALYST – 16996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10Roof Technology</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Data Scientist, and a UI Developer. Great atti...</td>\n",
       "      <td>Big Data Developer (Spark, Hadoop, Hive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>Validate data models (logical and physical) fo...</td>\n",
       "      <td>Government Enterprise Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lauren Enterprises</td>\n",
       "      <td>Denver, CO 80226</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Looking for a Food Scientist:. Secondary and/o...</td>\n",
       "      <td>Food Scientist: Chemistry &amp; Formulations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Denver Health</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>88091.0</td>\n",
       "      <td>Budget development, processing and monitoring ...</td>\n",
       "      <td>Business Manager - RADARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>56500.0</td>\n",
       "      <td>Research information and data problems. Certif...</td>\n",
       "      <td>Bioinformationist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Of visiting scientists; In use of excel, data ...</td>\n",
       "      <td>Managing Director for STROBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Potatoes USA</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Extensive knowledge and experience analyzing s...</td>\n",
       "      <td>Global Marketing Manager - Food Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Denver Health</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>66654.0</td>\n",
       "      <td>Typically, one (1) or more years of healthcare...</td>\n",
       "      <td>RN-Statistical Research Specilist Nursing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>50500.0</td>\n",
       "      <td>Experience finding data and/or providing suppo...</td>\n",
       "      <td>Health &amp; Human Sciences Librarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G2 Web Services, LLC</td>\n",
       "      <td>Bellevue, WA 98004 (Downtown area)</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Capture and record data in G2’s proprietary so...</td>\n",
       "      <td>Research and Investigation Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Philanthropy Northwest</td>\n",
       "      <td>Seattle, WA 98121 (Belltown area)</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Conduct research and provide data analysis in ...</td>\n",
       "      <td>Research Analyst, The Giving Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dynamic Staffing Inc.</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Exposure to big data systems (Hadoop, HBASE, H...</td>\n",
       "      <td>Data Scientist-Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HERO.Jobs</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Build big data, machine learning applications ...</td>\n",
       "      <td>Machine Learning Engineer - Big Data, Python, R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>Working with a team of Analysts, Software Deve...</td>\n",
       "      <td>Sr. Global Device Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cutting Edge Medical Diagnostics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Data and image analysis using advanced statist...</td>\n",
       "      <td>Sr. Data Scientist / Machine Learning (In-vitr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>State of Washington</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>55548.0</td>\n",
       "      <td>Performing field surveys or studies, 2) respon...</td>\n",
       "      <td>TMDL Lead (Environmental Specialist 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>Variant Scientist (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>The Medical Image Analysis Scientist, works wi...</td>\n",
       "      <td>Scientist, Med Imag Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Synergy Search Group</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Duties will include data conversion from multi...</td>\n",
       "      <td>Audit Snr (Banking) - Data Analysis 60K-80K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Georgia Department of Public Health</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Under broad supervision, assists technicians a...</td>\n",
       "      <td>Laboratory Aide 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>66700.0</td>\n",
       "      <td>Responsible for post award processing of grant...</td>\n",
       "      <td>Sponsored Research Financial Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Interesse International Inc</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Estimate numerical data; Must see through the ...</td>\n",
       "      <td>Market Research &amp; Sales Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Bayone Solutions Inc.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Position - Data Scientist - Recommendation Eng...</td>\n",
       "      <td>Data Scientist - Recommendation Engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Nisum Technologies</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Big Data Stack:. Hadoop data Ingestion, data q...</td>\n",
       "      <td>Big Data Talend Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Federal Emergency Management Agency</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>96947.0</td>\n",
       "      <td>In this position, you will serve as a Physical...</td>\n",
       "      <td>Physical Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>The Data Scientist will join a very senior tea...</td>\n",
       "      <td>Data Scientist (Image Processing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>They are seeking a Data Scientist to join thei...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Corporate Labs Technology</td>\n",
       "      <td>Brisbane, CA</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>Natural Language Processing Brisbane, CA Sign ...</td>\n",
       "      <td>Data Scientist (Natural Language Processing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>A leading San Francisco consumer web and perso...</td>\n",
       "      <td>Data Scientist (Human Computation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Established retail and eCommerce company in do...</td>\n",
       "      <td>Senior Data Scientist (Optimization)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>A fast growing company located in Redwood City...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>The Principal Data Scientist will be working o...</td>\n",
       "      <td>Principal Data Scientist (Recommendation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>San Francisco Department of Public Health</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>111774.0</td>\n",
       "      <td>Under administrative direction of the Director...</td>\n",
       "      <td>Manager I - Chief Microbiologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>This group works alongside the algorithms R&amp;D ...</td>\n",
       "      <td>Senior Data Engineer- Algorithms Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Corporate Labs Technology</td>\n",
       "      <td>Brisbane, CA</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>Machine Learning Developer Brisbane, CA Sign o...</td>\n",
       "      <td>Data Scientist (Machine Learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Harnham</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>You will lead a team of 4 data scientists incl...</td>\n",
       "      <td>Senior Data Science Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>The Data Scientist will have an opportunity to...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>A fast growing company located in Redwood City...</td>\n",
       "      <td>Data Scientist- cool startup in RedWood City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>The Senior Data Engineer will be working along...</td>\n",
       "      <td>Senior Data Engineer - Recommendation Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Data Mining Experience. The Data Engineers wor...</td>\n",
       "      <td>Data Engineer (Python)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Machine Learning Senior Data Scientist. Mentor...</td>\n",
       "      <td>Sr. Machine Learning Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Averity</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>Enabling our Data Scientists to create product...</td>\n",
       "      <td>Executive Director of Data Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>A San Francisco-based agriculture software com...</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>University of California Berkeley</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Enforces EI’s confidential data access policy....</td>\n",
       "      <td>Office Manager, Energy Institute at Haas ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>Proven experience with Business Intelligence t...</td>\n",
       "      <td>Strategic Research Opportunities Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>IGE Therapeutics, Inc</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>The candidates working in a Team culture, are ...</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Experience working with large amounts of data....</td>\n",
       "      <td>Software Engineer (C#/Machine Learning)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       company  \\\n",
       "0                        Gunther Douglas, Inc.   \n",
       "1                        Denver Public Schools   \n",
       "2                                Mountain Ltd.   \n",
       "3          tronc (formerly Tribune Publishing)   \n",
       "4                                           LT   \n",
       "5                                    Codesmith   \n",
       "6                       Geode Executive Search   \n",
       "7                       Scienaptic Systems Inc   \n",
       "8                                 Wade & Wendy   \n",
       "9                                   Dashbot.io   \n",
       "10                 Community College of Aurora   \n",
       "11                       Denver Public Schools   \n",
       "12                           10Roof Technology   \n",
       "13                         xentity corporation   \n",
       "14                          Lauren Enterprises   \n",
       "15                               Denver Health   \n",
       "16                      University of Colorado   \n",
       "17                      University of Colorado   \n",
       "18                                Potatoes USA   \n",
       "19                               Denver Health   \n",
       "20                      University of Colorado   \n",
       "21                        G2 Web Services, LLC   \n",
       "22                      Philanthropy Northwest   \n",
       "23                       Dynamic Staffing Inc.   \n",
       "24                                   HERO.Jobs   \n",
       "25                       Smith Arnold Partners   \n",
       "26                            All-In Analytics   \n",
       "27            Cutting Edge Medical Diagnostics   \n",
       "28                         State of Washington   \n",
       "29                       Lighthouse Recruiting   \n",
       "..                                         ...   \n",
       "116                           Emory University   \n",
       "117                       Synergy Search Group   \n",
       "118        Georgia Department of Public Health   \n",
       "119                           Emory University   \n",
       "120                Interesse International Inc   \n",
       "121                      Bayone Solutions Inc.   \n",
       "122                         Nisum Technologies   \n",
       "123        Federal Emergency Management Agency   \n",
       "124                      Workbridge Associates   \n",
       "125                      Workbridge Associates   \n",
       "126                  Corporate Labs Technology   \n",
       "127                      Workbridge Associates   \n",
       "128                      Workbridge Associates   \n",
       "129                         Jobspring Partners   \n",
       "130                      Workbridge Associates   \n",
       "131  San Francisco Department of Public Health   \n",
       "132                      Workbridge Associates   \n",
       "133                  Corporate Labs Technology   \n",
       "134                                    Harnham   \n",
       "135                      Workbridge Associates   \n",
       "136                         Jobspring Partners   \n",
       "137                      Workbridge Associates   \n",
       "138                      Workbridge Associates   \n",
       "139                           All-In Analytics   \n",
       "140                                    Averity   \n",
       "141                      Workbridge Associates   \n",
       "142          University of California Berkeley   \n",
       "143                               UC San Diego   \n",
       "144                      IGE Therapeutics, Inc   \n",
       "145                      Workbridge Associates   \n",
       "\n",
       "                                        location    salary  \\\n",
       "0                                   Superior, CO  112500.0   \n",
       "1    Denver, CO 80204 (Central West Denver area)   69673.0   \n",
       "2                                     Denver, CO   42500.0   \n",
       "3                                Los Angeles, CA   65000.0   \n",
       "4                                Los Angeles, CA  180000.0   \n",
       "5                                Los Angeles, CA  103000.0   \n",
       "6                                   New York, NY  200000.0   \n",
       "7                                   New York, NY  100000.0   \n",
       "8                                   New York, NY  100000.0   \n",
       "9                              San Francisco, CA  170000.0   \n",
       "10                                    Aurora, CO   40000.0   \n",
       "11                                    Denver, CO   63339.0   \n",
       "12                                    Denver, CO  105000.0   \n",
       "13                                    Denver, CO  111000.0   \n",
       "14                              Denver, CO 80226   35000.0   \n",
       "15   Denver, CO 80204 (Central West Denver area)   88091.0   \n",
       "16                                    Aurora, CO   56500.0   \n",
       "17                                   Boulder, CO  107500.0   \n",
       "18                                    Denver, CO   85000.0   \n",
       "19   Denver, CO 80204 (Central West Denver area)   66654.0   \n",
       "20                                   Boulder, CO   50500.0   \n",
       "21            Bellevue, WA 98004 (Downtown area)   35000.0   \n",
       "22             Seattle, WA 98121 (Belltown area)   55000.0   \n",
       "23                                   Seattle, WA  125000.0   \n",
       "24                                   Seattle, WA  160000.0   \n",
       "25                                   Seattle, WA   57500.0   \n",
       "26                                   Seattle, WA  162500.0   \n",
       "27                                   Seattle, WA  140000.0   \n",
       "28                                  Bellevue, WA   55548.0   \n",
       "29                                   Seattle, WA   95000.0   \n",
       "..                                           ...       ...   \n",
       "116                                  Atlanta, GA   69900.0   \n",
       "117                                  Atlanta, GA   80000.0   \n",
       "118                                  Atlanta, GA   24000.0   \n",
       "119                                  Atlanta, GA   66700.0   \n",
       "120                                  Atlanta, GA   65000.0   \n",
       "121                            San Francisco, CA  160000.0   \n",
       "122                            San Francisco, CA  140000.0   \n",
       "123                                  Oakland, CA   96947.0   \n",
       "124                            San Francisco, CA  145000.0   \n",
       "125                            San Francisco, CA  157500.0   \n",
       "126                                 Brisbane, CA  145000.0   \n",
       "127                            San Francisco, CA  150000.0   \n",
       "128                            San Francisco, CA  150000.0   \n",
       "129                             Redwood City, CA  160000.0   \n",
       "130                            San Francisco, CA  140000.0   \n",
       "131                            San Francisco, CA  111774.0   \n",
       "132                            San Francisco, CA  175000.0   \n",
       "133                                 Brisbane, CA  145000.0   \n",
       "134                            San Francisco, CA  185000.0   \n",
       "135                            San Francisco, CA  160000.0   \n",
       "136                             Redwood City, CA  165000.0   \n",
       "137                            San Francisco, CA  160000.0   \n",
       "138                            San Francisco, CA  150000.0   \n",
       "139                            San Francisco, CA  135000.0   \n",
       "140                            San Francisco, CA  205000.0   \n",
       "141                            San Francisco, CA  180000.0   \n",
       "142                                 Berkeley, CA   70000.0   \n",
       "143                                San Diego, CA   68200.0   \n",
       "144                                San Diego, CA   53000.0   \n",
       "145                                San Diego, CA  100000.0   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Gunther Douglas’ client is seeking a Data Scie...   \n",
       "1    Clean data for analysis. Develop data collecti...   \n",
       "2    Enter data from legal sources into database. I...   \n",
       "3    Partner with data scientists in the Technology...   \n",
       "4    Our data team consists of two data analysts an...   \n",
       "5    We are now bringing this same groundbreaking a...   \n",
       "6    Data Scientist - Text Analytics - SQL, R, SAS*...   \n",
       "7    We are looking for an energetic and experience...   \n",
       "8    Our Data Scientist will integrate data from we...   \n",
       "9    Data migration, transformation, and scripting....   \n",
       "10   Works with large complex data sets, including ...   \n",
       "11   Fulfill internal data requests, and coordinate...   \n",
       "12   Data Scientist, and a UI Developer. Great atti...   \n",
       "13   Validate data models (logical and physical) fo...   \n",
       "14   Looking for a Food Scientist:. Secondary and/o...   \n",
       "15   Budget development, processing and monitoring ...   \n",
       "16   Research information and data problems. Certif...   \n",
       "17   Of visiting scientists; In use of excel, data ...   \n",
       "18   Extensive knowledge and experience analyzing s...   \n",
       "19   Typically, one (1) or more years of healthcare...   \n",
       "20   Experience finding data and/or providing suppo...   \n",
       "21   Capture and record data in G2’s proprietary so...   \n",
       "22   Conduct research and provide data analysis in ...   \n",
       "23   Exposure to big data systems (Hadoop, HBASE, H...   \n",
       "24   Build big data, machine learning applications ...   \n",
       "25   Growing international custom research supplier...   \n",
       "26   Working with a team of Analysts, Software Deve...   \n",
       "27   Data and image analysis using advanced statist...   \n",
       "28   Performing field surveys or studies, 2) respon...   \n",
       "29   Join our Medical Laboratory Scientists Groups:...   \n",
       "..                                                 ...   \n",
       "116  The Medical Image Analysis Scientist, works wi...   \n",
       "117  Duties will include data conversion from multi...   \n",
       "118  Under broad supervision, assists technicians a...   \n",
       "119  Responsible for post award processing of grant...   \n",
       "120  Estimate numerical data; Must see through the ...   \n",
       "121  Position - Data Scientist - Recommendation Eng...   \n",
       "122  Big Data Stack:. Hadoop data Ingestion, data q...   \n",
       "123  In this position, you will serve as a Physical...   \n",
       "124  The Data Scientist will join a very senior tea...   \n",
       "125  They are seeking a Data Scientist to join thei...   \n",
       "126  Natural Language Processing Brisbane, CA Sign ...   \n",
       "127  A leading San Francisco consumer web and perso...   \n",
       "128  Established retail and eCommerce company in do...   \n",
       "129  A fast growing company located in Redwood City...   \n",
       "130  The Principal Data Scientist will be working o...   \n",
       "131  Under administrative direction of the Director...   \n",
       "132  This group works alongside the algorithms R&D ...   \n",
       "133  Machine Learning Developer Brisbane, CA Sign o...   \n",
       "134  You will lead a team of 4 data scientists incl...   \n",
       "135  The Data Scientist will have an opportunity to...   \n",
       "136  A fast growing company located in Redwood City...   \n",
       "137  The Senior Data Engineer will be working along...   \n",
       "138  Data Mining Experience. The Data Engineers wor...   \n",
       "139  Machine Learning Senior Data Scientist. Mentor...   \n",
       "140  Enabling our Data Scientists to create product...   \n",
       "141  A San Francisco-based agriculture software com...   \n",
       "142  Enforces EI’s confidential data access policy....   \n",
       "143  Proven experience with Business Intelligence t...   \n",
       "144  The candidates working in a Team culture, are ...   \n",
       "145  Experience working with large amounts of data....   \n",
       "\n",
       "                                                 title  \n",
       "0                                       Data Scientist  \n",
       "1    SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...  \n",
       "2                               Legal Research Analyst  \n",
       "3                  Social Media Marketing Data Analyst  \n",
       "4                                Senior Data Scientist  \n",
       "5          Senior Data Science Engineer and Instructor  \n",
       "6        Data Scientist - Text Analytics - SQL, R, SAS  \n",
       "7                                       Data Scientist  \n",
       "8                 Wade & Wendy_Data Scientist/Engineer  \n",
       "9                          Data Engineer and Scientist  \n",
       "10                                    Research Analyst  \n",
       "11                            RESEARCH ANALYST – 16996  \n",
       "12            Big Data Developer (Spark, Hadoop, Hive)  \n",
       "13                     Government Enterprise Architect  \n",
       "14            Food Scientist: Chemistry & Formulations  \n",
       "15                           Business Manager - RADARS  \n",
       "16                                   Bioinformationist  \n",
       "17                        Managing Director for STROBE  \n",
       "18       Global Marketing Manager - Food Manufacturing  \n",
       "19           RN-Statistical Research Specilist Nursing  \n",
       "20                   Health & Human Sciences Librarian  \n",
       "21                  Research and Investigation Analyst  \n",
       "22               Research Analyst, The Giving Practice  \n",
       "23                    Data Scientist-Software Engineer  \n",
       "24     Machine Learning Engineer - Big Data, Python, R  \n",
       "25                                    Research Analyst  \n",
       "26                           Sr. Global Device Manager  \n",
       "27   Sr. Data Scientist / Machine Learning (In-vitr...  \n",
       "28              TMDL Lead (Environmental Specialist 4)  \n",
       "29                          Variant Scientist (Remote)  \n",
       "..                                                 ...  \n",
       "116                       Scientist, Med Imag Analysis  \n",
       "117        Audit Snr (Banking) - Data Analysis 60K-80K  \n",
       "118                                  Laboratory Aide 3  \n",
       "119               Sponsored Research Financial Analyst  \n",
       "120                    Market Research & Sales Analyst  \n",
       "121             Data Scientist - Recommendation Engine  \n",
       "122                          Big Data Talend Developer  \n",
       "123                                 Physical Scientist  \n",
       "124                  Data Scientist (Image Processing)  \n",
       "125                                     Data Scientist  \n",
       "126       Data Scientist (Natural Language Processing)  \n",
       "127                 Data Scientist (Human Computation)  \n",
       "128               Senior Data Scientist (Optimization)  \n",
       "129                                     Data Scientist  \n",
       "130          Principal Data Scientist (Recommendation)  \n",
       "131                   Manager I - Chief Microbiologist  \n",
       "132          Senior Data Engineer- Algorithms Platform  \n",
       "133                  Data Scientist (Machine Learning)  \n",
       "134                        Senior Data Science Manager  \n",
       "135                              Senior Data Scientist  \n",
       "136       Data Scientist- cool startup in RedWood City  \n",
       "137     Senior Data Engineer - Recommendation Platform  \n",
       "138                             Data Engineer (Python)  \n",
       "139                Sr. Machine Learning Data Scientist  \n",
       "140             Executive Director of Data Engineering  \n",
       "141                           Principal Data Scientist  \n",
       "142         Office Manager, Energy Institute at Haas ,  \n",
       "143           Strategic Research Opportunities Analyst  \n",
       "144                                          Scientist  \n",
       "145            Software Engineer (C#/Machine Learning)  \n",
       "\n",
       "[146 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_index = new_data.reset_index(drop=True)\n",
    "new_data_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "5d66eb8a-a032-43f7-8e87-8f37612c2ce5"
   },
   "outputs": [],
   "source": [
    "# save scraped results as a CSV for Tableau/external viz\n",
    "new_data_index.to_csv('DS_New_Salaries.csv', encoding = 'utf-8')"
=======
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "6e8a5a1c-1580-4845-a9b6-482bc00c73cd"
   },
   "source": [
    "## Predicting salaries using Logistic Regression"
=======
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "634ab7c1-c76f-4b04-a36e-5ff3cb1f9eb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>salary</th>\n",
       "      <th>summary</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gunther Douglas, Inc.</td>\n",
       "      <td>Superior, CO</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>Gunther Douglas’ client is seeking a Data Scie...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>69673.0</td>\n",
       "      <td>Clean data for analysis. Develop data collecti...</td>\n",
       "      <td>SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mountain Ltd.</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>42500.0</td>\n",
       "      <td>Enter data from legal sources into database. I...</td>\n",
       "      <td>Legal Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tronc (formerly Tribune Publishing)</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Partner with data scientists in the Technology...</td>\n",
       "      <td>Social Media Marketing Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LT</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Our data team consists of two data analysts an...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Codesmith</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>103000.0</td>\n",
       "      <td>We are now bringing this same groundbreaking a...</td>\n",
       "      <td>Senior Data Science Engineer and Instructor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Geode Executive Search</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>Data Scientist - Text Analytics - SQL, R, SAS*...</td>\n",
       "      <td>Data Scientist - Text Analytics - SQL, R, SAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Scienaptic Systems Inc</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>We are looking for an energetic and experience...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wade &amp; Wendy</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Our Data Scientist will integrate data from we...</td>\n",
       "      <td>Wade &amp; Wendy_Data Scientist/Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dashbot.io</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>170000.0</td>\n",
       "      <td>Data migration, transformation, and scripting....</td>\n",
       "      <td>Data Engineer and Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Community College of Aurora</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Works with large complex data sets, including ...</td>\n",
       "      <td>Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Denver Public Schools</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>63339.0</td>\n",
       "      <td>Fulfill internal data requests, and coordinate...</td>\n",
       "      <td>RESEARCH ANALYST – 16996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10Roof Technology</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Data Scientist, and a UI Developer. Great atti...</td>\n",
       "      <td>Big Data Developer (Spark, Hadoop, Hive)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xentity corporation</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>111000.0</td>\n",
       "      <td>Validate data models (logical and physical) fo...</td>\n",
       "      <td>Government Enterprise Architect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lauren Enterprises</td>\n",
       "      <td>Denver, CO 80226</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Looking for a Food Scientist:. Secondary and/o...</td>\n",
       "      <td>Food Scientist: Chemistry &amp; Formulations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Denver Health</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>88091.0</td>\n",
       "      <td>Budget development, processing and monitoring ...</td>\n",
       "      <td>Business Manager - RADARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>56500.0</td>\n",
       "      <td>Research information and data problems. Certif...</td>\n",
       "      <td>Bioinformationist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>107500.0</td>\n",
       "      <td>Of visiting scientists; In use of excel, data ...</td>\n",
       "      <td>Managing Director for STROBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Potatoes USA</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Extensive knowledge and experience analyzing s...</td>\n",
       "      <td>Global Marketing Manager - Food Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Denver Health</td>\n",
       "      <td>Denver, CO 80204 (Central West Denver area)</td>\n",
       "      <td>66654.0</td>\n",
       "      <td>Typically, one (1) or more years of healthcare...</td>\n",
       "      <td>RN-Statistical Research Specilist Nursing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>University of Colorado</td>\n",
       "      <td>Boulder, CO</td>\n",
       "      <td>50500.0</td>\n",
       "      <td>Experience finding data and/or providing suppo...</td>\n",
       "      <td>Health &amp; Human Sciences Librarian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>G2 Web Services, LLC</td>\n",
       "      <td>Bellevue, WA 98004 (Downtown area)</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>Capture and record data in G2’s proprietary so...</td>\n",
       "      <td>Research and Investigation Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Philanthropy Northwest</td>\n",
       "      <td>Seattle, WA 98121 (Belltown area)</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Conduct research and provide data analysis in ...</td>\n",
       "      <td>Research Analyst, The Giving Practice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dynamic Staffing Inc.</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Exposure to big data systems (Hadoop, HBASE, H...</td>\n",
       "      <td>Data Scientist-Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HERO.Jobs</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Build big data, machine learning applications ...</td>\n",
       "      <td>Machine Learning Engineer - Big Data, Python, R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Smith Arnold Partners</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>57500.0</td>\n",
       "      <td>Growing international custom research supplier...</td>\n",
       "      <td>Research Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>162500.0</td>\n",
       "      <td>Working with a team of Analysts, Software Deve...</td>\n",
       "      <td>Sr. Global Device Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Cutting Edge Medical Diagnostics</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Data and image analysis using advanced statist...</td>\n",
       "      <td>Sr. Data Scientist / Machine Learning (In-vitr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>State of Washington</td>\n",
       "      <td>Bellevue, WA</td>\n",
       "      <td>55548.0</td>\n",
       "      <td>Performing field surveys or studies, 2) respon...</td>\n",
       "      <td>TMDL Lead (Environmental Specialist 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lighthouse Recruiting</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>Join our Medical Laboratory Scientists Groups:...</td>\n",
       "      <td>Variant Scientist (Remote)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>69900.0</td>\n",
       "      <td>The Medical Image Analysis Scientist, works wi...</td>\n",
       "      <td>Scientist, Med Imag Analysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Synergy Search Group</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>Duties will include data conversion from multi...</td>\n",
       "      <td>Audit Snr (Banking) - Data Analysis 60K-80K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Georgia Department of Public Health</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>Under broad supervision, assists technicians a...</td>\n",
       "      <td>Laboratory Aide 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Emory University</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>66700.0</td>\n",
       "      <td>Responsible for post award processing of grant...</td>\n",
       "      <td>Sponsored Research Financial Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Interesse International Inc</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Estimate numerical data; Must see through the ...</td>\n",
       "      <td>Market Research &amp; Sales Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Bayone Solutions Inc.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>Position - Data Scientist - Recommendation Eng...</td>\n",
       "      <td>Data Scientist - Recommendation Engine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Nisum Technologies</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Big Data Stack:. Hadoop data Ingestion, data q...</td>\n",
       "      <td>Big Data Talend Developer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Federal Emergency Management Agency</td>\n",
       "      <td>Oakland, CA</td>\n",
       "      <td>96947.0</td>\n",
       "      <td>In this position, you will serve as a Physical...</td>\n",
       "      <td>Physical Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>The Data Scientist will join a very senior tea...</td>\n",
       "      <td>Data Scientist (Image Processing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>They are seeking a Data Scientist to join thei...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Corporate Labs Technology</td>\n",
       "      <td>Brisbane, CA</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>Natural Language Processing Brisbane, CA Sign ...</td>\n",
       "      <td>Data Scientist (Natural Language Processing)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>A leading San Francisco consumer web and perso...</td>\n",
       "      <td>Data Scientist (Human Computation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Established retail and eCommerce company in do...</td>\n",
       "      <td>Senior Data Scientist (Optimization)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>A fast growing company located in Redwood City...</td>\n",
       "      <td>Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>The Principal Data Scientist will be working o...</td>\n",
       "      <td>Principal Data Scientist (Recommendation)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>San Francisco Department of Public Health</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>111774.0</td>\n",
       "      <td>Under administrative direction of the Director...</td>\n",
       "      <td>Manager I - Chief Microbiologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>175000.0</td>\n",
       "      <td>This group works alongside the algorithms R&amp;D ...</td>\n",
       "      <td>Senior Data Engineer- Algorithms Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Corporate Labs Technology</td>\n",
       "      <td>Brisbane, CA</td>\n",
       "      <td>145000.0</td>\n",
       "      <td>Machine Learning Developer Brisbane, CA Sign o...</td>\n",
       "      <td>Data Scientist (Machine Learning)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Harnham</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>You will lead a team of 4 data scientists incl...</td>\n",
       "      <td>Senior Data Science Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>The Data Scientist will have an opportunity to...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Jobspring Partners</td>\n",
       "      <td>Redwood City, CA</td>\n",
       "      <td>165000.0</td>\n",
       "      <td>A fast growing company located in Redwood City...</td>\n",
       "      <td>Data Scientist- cool startup in RedWood City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>160000.0</td>\n",
       "      <td>The Senior Data Engineer will be working along...</td>\n",
       "      <td>Senior Data Engineer - Recommendation Platform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Data Mining Experience. The Data Engineers wor...</td>\n",
       "      <td>Data Engineer (Python)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>All-In Analytics</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>Machine Learning Senior Data Scientist. Mentor...</td>\n",
       "      <td>Sr. Machine Learning Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Averity</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>205000.0</td>\n",
       "      <td>Enabling our Data Scientists to create product...</td>\n",
       "      <td>Executive Director of Data Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>A San Francisco-based agriculture software com...</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>University of California Berkeley</td>\n",
       "      <td>Berkeley, CA</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>Enforces EI’s confidential data access policy....</td>\n",
       "      <td>Office Manager, Energy Institute at Haas ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>UC San Diego</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>68200.0</td>\n",
       "      <td>Proven experience with Business Intelligence t...</td>\n",
       "      <td>Strategic Research Opportunities Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>IGE Therapeutics, Inc</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>53000.0</td>\n",
       "      <td>The candidates working in a Team culture, are ...</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Workbridge Associates</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>Experience working with large amounts of data....</td>\n",
       "      <td>Software Engineer (C#/Machine Learning)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>146 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       company  \\\n",
       "0                        Gunther Douglas, Inc.   \n",
       "1                        Denver Public Schools   \n",
       "2                                Mountain Ltd.   \n",
       "3          tronc (formerly Tribune Publishing)   \n",
       "4                                           LT   \n",
       "5                                    Codesmith   \n",
       "6                       Geode Executive Search   \n",
       "7                       Scienaptic Systems Inc   \n",
       "8                                 Wade & Wendy   \n",
       "9                                   Dashbot.io   \n",
       "10                 Community College of Aurora   \n",
       "11                       Denver Public Schools   \n",
       "12                           10Roof Technology   \n",
       "13                         xentity corporation   \n",
       "14                          Lauren Enterprises   \n",
       "15                               Denver Health   \n",
       "16                      University of Colorado   \n",
       "17                      University of Colorado   \n",
       "18                                Potatoes USA   \n",
       "19                               Denver Health   \n",
       "20                      University of Colorado   \n",
       "21                        G2 Web Services, LLC   \n",
       "22                      Philanthropy Northwest   \n",
       "23                       Dynamic Staffing Inc.   \n",
       "24                                   HERO.Jobs   \n",
       "25                       Smith Arnold Partners   \n",
       "26                            All-In Analytics   \n",
       "27            Cutting Edge Medical Diagnostics   \n",
       "28                         State of Washington   \n",
       "29                       Lighthouse Recruiting   \n",
       "..                                         ...   \n",
       "116                           Emory University   \n",
       "117                       Synergy Search Group   \n",
       "118        Georgia Department of Public Health   \n",
       "119                           Emory University   \n",
       "120                Interesse International Inc   \n",
       "121                      Bayone Solutions Inc.   \n",
       "122                         Nisum Technologies   \n",
       "123        Federal Emergency Management Agency   \n",
       "124                      Workbridge Associates   \n",
       "125                      Workbridge Associates   \n",
       "126                  Corporate Labs Technology   \n",
       "127                      Workbridge Associates   \n",
       "128                      Workbridge Associates   \n",
       "129                         Jobspring Partners   \n",
       "130                      Workbridge Associates   \n",
       "131  San Francisco Department of Public Health   \n",
       "132                      Workbridge Associates   \n",
       "133                  Corporate Labs Technology   \n",
       "134                                    Harnham   \n",
       "135                      Workbridge Associates   \n",
       "136                         Jobspring Partners   \n",
       "137                      Workbridge Associates   \n",
       "138                      Workbridge Associates   \n",
       "139                           All-In Analytics   \n",
       "140                                    Averity   \n",
       "141                      Workbridge Associates   \n",
       "142          University of California Berkeley   \n",
       "143                               UC San Diego   \n",
       "144                      IGE Therapeutics, Inc   \n",
       "145                      Workbridge Associates   \n",
       "\n",
       "                                        location    salary  \\\n",
       "0                                   Superior, CO  112500.0   \n",
       "1    Denver, CO 80204 (Central West Denver area)   69673.0   \n",
       "2                                     Denver, CO   42500.0   \n",
       "3                                Los Angeles, CA   65000.0   \n",
       "4                                Los Angeles, CA  180000.0   \n",
       "5                                Los Angeles, CA  103000.0   \n",
       "6                                   New York, NY  200000.0   \n",
       "7                                   New York, NY  100000.0   \n",
       "8                                   New York, NY  100000.0   \n",
       "9                              San Francisco, CA  170000.0   \n",
       "10                                    Aurora, CO   40000.0   \n",
       "11                                    Denver, CO   63339.0   \n",
       "12                                    Denver, CO  105000.0   \n",
       "13                                    Denver, CO  111000.0   \n",
       "14                              Denver, CO 80226   35000.0   \n",
       "15   Denver, CO 80204 (Central West Denver area)   88091.0   \n",
       "16                                    Aurora, CO   56500.0   \n",
       "17                                   Boulder, CO  107500.0   \n",
       "18                                    Denver, CO   85000.0   \n",
       "19   Denver, CO 80204 (Central West Denver area)   66654.0   \n",
       "20                                   Boulder, CO   50500.0   \n",
       "21            Bellevue, WA 98004 (Downtown area)   35000.0   \n",
       "22             Seattle, WA 98121 (Belltown area)   55000.0   \n",
       "23                                   Seattle, WA  125000.0   \n",
       "24                                   Seattle, WA  160000.0   \n",
       "25                                   Seattle, WA   57500.0   \n",
       "26                                   Seattle, WA  162500.0   \n",
       "27                                   Seattle, WA  140000.0   \n",
       "28                                  Bellevue, WA   55548.0   \n",
       "29                                   Seattle, WA   95000.0   \n",
       "..                                           ...       ...   \n",
       "116                                  Atlanta, GA   69900.0   \n",
       "117                                  Atlanta, GA   80000.0   \n",
       "118                                  Atlanta, GA   24000.0   \n",
       "119                                  Atlanta, GA   66700.0   \n",
       "120                                  Atlanta, GA   65000.0   \n",
       "121                            San Francisco, CA  160000.0   \n",
       "122                            San Francisco, CA  140000.0   \n",
       "123                                  Oakland, CA   96947.0   \n",
       "124                            San Francisco, CA  145000.0   \n",
       "125                            San Francisco, CA  157500.0   \n",
       "126                                 Brisbane, CA  145000.0   \n",
       "127                            San Francisco, CA  150000.0   \n",
       "128                            San Francisco, CA  150000.0   \n",
       "129                             Redwood City, CA  160000.0   \n",
       "130                            San Francisco, CA  140000.0   \n",
       "131                            San Francisco, CA  111774.0   \n",
       "132                            San Francisco, CA  175000.0   \n",
       "133                                 Brisbane, CA  145000.0   \n",
       "134                            San Francisco, CA  185000.0   \n",
       "135                            San Francisco, CA  160000.0   \n",
       "136                             Redwood City, CA  165000.0   \n",
       "137                            San Francisco, CA  160000.0   \n",
       "138                            San Francisco, CA  150000.0   \n",
       "139                            San Francisco, CA  135000.0   \n",
       "140                            San Francisco, CA  205000.0   \n",
       "141                            San Francisco, CA  180000.0   \n",
       "142                                 Berkeley, CA   70000.0   \n",
       "143                                San Diego, CA   68200.0   \n",
       "144                                San Diego, CA   53000.0   \n",
       "145                                San Diego, CA  100000.0   \n",
       "\n",
       "                                               summary  \\\n",
       "0    Gunther Douglas’ client is seeking a Data Scie...   \n",
       "1    Clean data for analysis. Develop data collecti...   \n",
       "2    Enter data from legal sources into database. I...   \n",
       "3    Partner with data scientists in the Technology...   \n",
       "4    Our data team consists of two data analysts an...   \n",
       "5    We are now bringing this same groundbreaking a...   \n",
       "6    Data Scientist - Text Analytics - SQL, R, SAS*...   \n",
       "7    We are looking for an energetic and experience...   \n",
       "8    Our Data Scientist will integrate data from we...   \n",
       "9    Data migration, transformation, and scripting....   \n",
       "10   Works with large complex data sets, including ...   \n",
       "11   Fulfill internal data requests, and coordinate...   \n",
       "12   Data Scientist, and a UI Developer. Great atti...   \n",
       "13   Validate data models (logical and physical) fo...   \n",
       "14   Looking for a Food Scientist:. Secondary and/o...   \n",
       "15   Budget development, processing and monitoring ...   \n",
       "16   Research information and data problems. Certif...   \n",
       "17   Of visiting scientists; In use of excel, data ...   \n",
       "18   Extensive knowledge and experience analyzing s...   \n",
       "19   Typically, one (1) or more years of healthcare...   \n",
       "20   Experience finding data and/or providing suppo...   \n",
       "21   Capture and record data in G2’s proprietary so...   \n",
       "22   Conduct research and provide data analysis in ...   \n",
       "23   Exposure to big data systems (Hadoop, HBASE, H...   \n",
       "24   Build big data, machine learning applications ...   \n",
       "25   Growing international custom research supplier...   \n",
       "26   Working with a team of Analysts, Software Deve...   \n",
       "27   Data and image analysis using advanced statist...   \n",
       "28   Performing field surveys or studies, 2) respon...   \n",
       "29   Join our Medical Laboratory Scientists Groups:...   \n",
       "..                                                 ...   \n",
       "116  The Medical Image Analysis Scientist, works wi...   \n",
       "117  Duties will include data conversion from multi...   \n",
       "118  Under broad supervision, assists technicians a...   \n",
       "119  Responsible for post award processing of grant...   \n",
       "120  Estimate numerical data; Must see through the ...   \n",
       "121  Position - Data Scientist - Recommendation Eng...   \n",
       "122  Big Data Stack:. Hadoop data Ingestion, data q...   \n",
       "123  In this position, you will serve as a Physical...   \n",
       "124  The Data Scientist will join a very senior tea...   \n",
       "125  They are seeking a Data Scientist to join thei...   \n",
       "126  Natural Language Processing Brisbane, CA Sign ...   \n",
       "127  A leading San Francisco consumer web and perso...   \n",
       "128  Established retail and eCommerce company in do...   \n",
       "129  A fast growing company located in Redwood City...   \n",
       "130  The Principal Data Scientist will be working o...   \n",
       "131  Under administrative direction of the Director...   \n",
       "132  This group works alongside the algorithms R&D ...   \n",
       "133  Machine Learning Developer Brisbane, CA Sign o...   \n",
       "134  You will lead a team of 4 data scientists incl...   \n",
       "135  The Data Scientist will have an opportunity to...   \n",
       "136  A fast growing company located in Redwood City...   \n",
       "137  The Senior Data Engineer will be working along...   \n",
       "138  Data Mining Experience. The Data Engineers wor...   \n",
       "139  Machine Learning Senior Data Scientist. Mentor...   \n",
       "140  Enabling our Data Scientists to create product...   \n",
       "141  A San Francisco-based agriculture software com...   \n",
       "142  Enforces EI’s confidential data access policy....   \n",
       "143  Proven experience with Business Intelligence t...   \n",
       "144  The candidates working in a Team culture, are ...   \n",
       "145  Experience working with large amounts of data....   \n",
       "\n",
       "                                                 title  \n",
       "0                                       Data Scientist  \n",
       "1    SENIOR RESEARCH ANALYST, TEACHING AND LEARNING...  \n",
       "2                               Legal Research Analyst  \n",
       "3                  Social Media Marketing Data Analyst  \n",
       "4                                Senior Data Scientist  \n",
       "5          Senior Data Science Engineer and Instructor  \n",
       "6        Data Scientist - Text Analytics - SQL, R, SAS  \n",
       "7                                       Data Scientist  \n",
       "8                 Wade & Wendy_Data Scientist/Engineer  \n",
       "9                          Data Engineer and Scientist  \n",
       "10                                    Research Analyst  \n",
       "11                            RESEARCH ANALYST – 16996  \n",
       "12            Big Data Developer (Spark, Hadoop, Hive)  \n",
       "13                     Government Enterprise Architect  \n",
       "14            Food Scientist: Chemistry & Formulations  \n",
       "15                           Business Manager - RADARS  \n",
       "16                                   Bioinformationist  \n",
       "17                        Managing Director for STROBE  \n",
       "18       Global Marketing Manager - Food Manufacturing  \n",
       "19           RN-Statistical Research Specilist Nursing  \n",
       "20                   Health & Human Sciences Librarian  \n",
       "21                  Research and Investigation Analyst  \n",
       "22               Research Analyst, The Giving Practice  \n",
       "23                    Data Scientist-Software Engineer  \n",
       "24     Machine Learning Engineer - Big Data, Python, R  \n",
       "25                                    Research Analyst  \n",
       "26                           Sr. Global Device Manager  \n",
       "27   Sr. Data Scientist / Machine Learning (In-vitr...  \n",
       "28              TMDL Lead (Environmental Specialist 4)  \n",
       "29                          Variant Scientist (Remote)  \n",
       "..                                                 ...  \n",
       "116                       Scientist, Med Imag Analysis  \n",
       "117        Audit Snr (Banking) - Data Analysis 60K-80K  \n",
       "118                                  Laboratory Aide 3  \n",
       "119               Sponsored Research Financial Analyst  \n",
       "120                    Market Research & Sales Analyst  \n",
       "121             Data Scientist - Recommendation Engine  \n",
       "122                          Big Data Talend Developer  \n",
       "123                                 Physical Scientist  \n",
       "124                  Data Scientist (Image Processing)  \n",
       "125                                     Data Scientist  \n",
       "126       Data Scientist (Natural Language Processing)  \n",
       "127                 Data Scientist (Human Computation)  \n",
       "128               Senior Data Scientist (Optimization)  \n",
       "129                                     Data Scientist  \n",
       "130          Principal Data Scientist (Recommendation)  \n",
       "131                   Manager I - Chief Microbiologist  \n",
       "132          Senior Data Engineer- Algorithms Platform  \n",
       "133                  Data Scientist (Machine Learning)  \n",
       "134                        Senior Data Science Manager  \n",
       "135                              Senior Data Scientist  \n",
       "136       Data Scientist- cool startup in RedWood City  \n",
       "137     Senior Data Engineer - Recommendation Platform  \n",
       "138                             Data Engineer (Python)  \n",
       "139                Sr. Machine Learning Data Scientist  \n",
       "140             Executive Director of Data Engineering  \n",
       "141                           Principal Data Scientist  \n",
       "142         Office Manager, Energy Institute at Haas ,  \n",
       "143           Strategic Research Opportunities Analyst  \n",
       "144                                          Scientist  \n",
       "145            Software Engineer (C#/Machine Learning)  \n",
       "\n",
       "[146 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in the the data of scraped salaries\n",
    "new_data_index"
=======
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "c3ed6de7-8fe0-4cf4-abbd-abb2a188e05b"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)"
=======
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't have to choice the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "073e3f3e-21bc-4ab7-ae2e-272be0a409cc"
   },
   "outputs": [],
   "source": [
    "# calculate median and create feature with 1 as high salary\n",
    "\n",
    "median_data = new_data_index['salary'].median()\n",
    "median_data\n",
    "new_data_index['High_Low'] = new_data_index['salary'].map(lambda x: 1 if x >= 103854.25 else 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    73\n",
       "0    73\n",
       "Name: High_Low, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_index['High_Low'].value_counts()\n"
=======
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "3c7ec3d2-87a0-4290-9d83-a6f4a9ae7e9c"
   },
   "source": [
    "### Q: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "987666b2-d8e6-4715-b499-c9d314fb70ce"
   },
   "source": [
    "It is 50% if we guess randomly, half the salaries will be below the median and half will be above."
=======
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "ea7e00cb-9956-44ec-b585-7b95f4d6284c"
=======
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
>>>>>>> origin/master
   },
   "source": [
    "#### Create a Logistic Regression model to predict High/Low salary using statsmodel. Start by ONLY using the location as a feature. Display the coefficients and write a short summary of what they mean."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ce9161b3-eff3-475c-a087-a2be38d7f626"
   },
   "outputs": [],
   "source": [
    "# create statsmodel and summary\n",
    "import statsmodels.formula.api as sm\n"
=======
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "1ecd7811-d200-44bc-942f-4beb76d2689c"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' or 'Manager' is in the title \n",
=======
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title \n",
    "- or whether 'Manager' is in the title. \n",
>>>>>>> origin/master
    "- Then build a new Logistic Regression model with these features. Do they add any value? \n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b847f46e-1626-4340-86fb-08dea8c31a84"
   },
   "outputs": [],
   "source": [
    "# create senior, director, and manager dummies\n",
    "salary_data['is_senior'] = salary_data['title'].str.contains('Senior').astype(int) # example\n"
=======
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "068dc1cf-7fd7-4f27-a1f1-7f0a5a221d29"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "7ca5cfdd-958c-4199-aafa-3d3f6c5ba3c4"
=======
    "id": "9c9274ef-c9f5-4d56-b286-ecc8709eff9f"
>>>>>>> origin/master
   },
   "source": [
    "#### Rebuild this model with scikit-learn.\n",
    "- You can either create the dummy features manually or use the `dmatrix` function from `patsy`\n",
    "- Remember to scale the feature variables as well!\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "c75a97f1-f30c-48b3-97cb-eaf7d525c734"
   },
   "outputs": [],
   "source": [
    "# scale, (patsy optional), and fit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from patsy import dmatrix\n",
    "\n",
    "scaler = StandardScaler()\n",
    "model = LogisticRegression(penalty = 'l2', C=0.1)\n"
=======
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b76f65cd-cd3a-4e91-af55-12880be7b057"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "1e6c6902-2b4a-49f0-b4c7-935a26577d22"
=======
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
>>>>>>> origin/master
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy, AUC, precision and recall of the model. \n",
    "- Discuss the differences and explain when you want a high-recall or a high-precision model in this scenario."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "3667427c-6534-4dcd-8770-f492b0e3a39e"
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']: # example\n",
    "    "
=======
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "4263b1c0-bfde-42bf-ab45-71c7cd798835"
   },
   "source": [
    "### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
=======
    "id": "8c22664b-92e4-4fc2-b7ac-fbac865845d3"
   },
   "source": [
    "#### Compare L1 and L2 regularization for this logistic regression model. What effect does this have on the coefficients learned?"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "2e7d6a29-a515-468a-9953-9d73a0f81de0"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty = 'l1', C=1.0)\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    "
=======
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "172fd952-5012-4630-81f4-1206da6eb820"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "32d908a3-89d2-474c-a7f0-199bfae6da7e"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : X.design_info.column_names, 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)\n",
    "df"
=======
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "56cc8854-d722-411d-a6c7-e86310710f67"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
<<<<<<< HEAD
    "focus": true,
    "id": "82f16f60-6c8b-4376-b3ec-b8ec61a0cde7"
   },
   "source": [
    "#### Optional: Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients. Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary. Which entries have the highest predicted salaries?"
=======
    "focus": false,
    "id": "fead9b5b-7316-405d-87fd-e144dff0cbeb"
   },
   "source": [
    "#### Continue to incorporate other text features from the title or summary that you believe will predict the salary and examine their coefficients"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
<<<<<<< HEAD
    "id": "3f242a55-4518-4c95-ae90-6888c68077d3"
   },
   "source": [
    "# Bonus Section: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "757205dc-443d-4754-9d23-e591e0921c02"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform()\n",
    "\n",
    "for metric in ['accuracy', 'precision', 'recall', 'roc_auc']:\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=3, scoring=metric)\n",
    "    print(metric, scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "f44df3c1-cf82-4271-8660-fdd0052097b6"
   },
   "outputs": [],
   "source": [
    "model.fit(X_scaled, y)\n",
    "\n",
    "df = pd.DataFrame({'features' : vectorizer.get_feature_names(), 'coef': model.coef_[0,:]})\n",
    "df.sort_values('coef', ascending=False, inplace=True)"
=======
    "id": "12d5edeb-a272-43a0-9977-d951f12fedfb"
   },
   "source": [
    "#### Take ~100 scraped entries with salaries. Convert them to use with your model and predict the salary - which entries have the highest predicted salaries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the text summaries. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate the logistic regression model using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "e182bbe4-2a72-4e75-a3e8-c117688cb8a6"
   },
   "outputs": [],
   "source": [
    "df.head()"
=======
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a15ef8ea-3130-4c08-a165-ac34d2a8d829"
   },
   "outputs": [],
   "source": [
    "df.tail()"
=======
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "fec80936-37bc-4922-89bd-b5d615566c9c"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "d42b9fd8-39d5-416a-b40b-7410e6396c11"
   },
   "source": [
    "#### Re-test L1 and L2 regularization. You can use LogisticRegressionCV to find the optimal reguarlization parameters. \n",
    "- Re-test what text features are most valuable.  \n",
    "- How do L1 and L2 change the coefficients?"
>>>>>>> origin/master
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "b8a13337-0cde-4117-a928-ffae14661453"
   },
   "outputs": [],
   "source": [
    "# retest L1 and L2 regularization\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "model = LogisticRegressionCV()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "936cd752-6b3f-450f-bfb6-1659c6e71539"
   },
   "source": [
    "Score: | /24\n",
    "------|-------\n",
    "Identify: Problem Statement and Hypothesis | \n",
    "Acquire: Import Data using BeautifulSoup| \n",
    "Parse: Clean and Organize Data| \n",
    "Model: Perform Logistic Regression| \n",
    "Evaluate: Logistic Regression Results\t|\n",
    "Present: Blog Report with Findings and Recommendations\t\t| \n",
    "Interactive Tableau visualizations | \n",
    "Regularization |\n",
    "Bonus: Countvectorizer  | "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
=======
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "7570e237-c8cc-4e26-b569-7aee10627e79"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "e3a0c83d-e3b8-4bed-b864-7e795b34a3d4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
>>>>>>> origin/master
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
