{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreate the data we used in the previous Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "column_names = ['id',\n",
    "                'clump_thickness',\n",
    "                'cell_size_uniformity',\n",
    "                'cell_shape_uniformity',\n",
    "                'marginal_adhesion',\n",
    "                'single_epithelial_size',\n",
    "                'bare_nuclei',\n",
    "                'bland_chromatin',\n",
    "                'normal_nucleoli',\n",
    "                'mitoses',\n",
    "                'class']\n",
    "\n",
    "bcw = pd.read_csv('../assets/datasets/breast-cancer-wisconsin.csv',\n",
    "                 names=column_names, na_values=['?'])\n",
    "\n",
    "bcw.dropna(inplace=True)\n",
    "bcw['metrics_pct'] = bcw[[x for x in column_names if x not in ['class','id']]].sum(axis=1)/90.\n",
    "bcw['class'] = bcw['class'].map(lambda x: 0 if x == 2 else 1)\n",
    "\n",
    "metrics_pct = np.array(bcw.metrics_pct.values)\n",
    "metrics_pct = metrics_pct[:, np.newaxis]\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(metrics_pct, bcw[['class']].values, \n",
    "                                                    test_size=0.33, stratify=bcw[['class']].values,\n",
    "                                                    random_state=77)\n",
    "\n",
    "logreg = LogisticRegression(random_state=77)\n",
    "logreg.fit(X_train, Y_train)\n",
    "Y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we use logreg.predict, what is actually happening here?\n",
    "\n",
    "The logreg model determines a **predicted probability** of class 0 and class 1 for each observation in the X_test matrix. These probabilities sum to 1 across classes. When predict is called, the standard behavior is to assign the class with the greater probability.\n",
    "\n",
    "Recreate the Y_pred vector manually from the predicted probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_0_pp  class_1_pp\n",
      "0    0.896571    0.103429\n",
      "1    0.086331    0.913669\n",
      "2    0.312713    0.687287\n",
      "3    0.920883    0.079117\n",
      "4    0.356408    0.643592\n",
      "5    0.876881    0.123119\n",
      "6    0.920883    0.079117\n",
      "7    0.913423    0.086577\n",
      "8    0.312713    0.687287\n",
      "9    0.133763    0.866237\n"
     ]
    }
   ],
   "source": [
    "# Get the predicted probability vector\n",
    "Y_pp = pd.DataFrame(logreg.predict_proba(X_test), columns=['class_0_pp','class_1_pp'])\n",
    "print(Y_pp.iloc[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This behavior is equivalent to a **classification threshold of 0.5 for class 1**. In other words, if class 1's predicted probability is >= 0.5, the observation is predicted to be class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_0_pp  class_1_pp  pred_class_thresh50\n",
      "0    0.896571    0.103429                    0\n",
      "1    0.086331    0.913669                    1\n",
      "2    0.312713    0.687287                    1\n",
      "3    0.920883    0.079117                    0\n",
      "4    0.356408    0.643592                    1\n",
      "5    0.876881    0.123119                    0\n",
      "6    0.920883    0.079117                    0\n",
      "7    0.913423    0.086577                    0\n",
      "8    0.312713    0.687287                    1\n",
      "9    0.133763    0.866237                    1\n"
     ]
    }
   ],
   "source": [
    "Y_pp['pred_class_thresh50'] = Y_pred\n",
    "print(Y_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say again that we are predicting cancer based on some kind of detection measure, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_cancer  predicted_healthy\n",
      "has_cancer                69                 10\n",
      "is_healthy                 4                143\n"
     ]
    }
   ],
   "source": [
    "conmat = np.array(confusion_matrix(Y_test, Y_pred, labels=[1,0]))\n",
    "\n",
    "confusion = pd.DataFrame(conmat, index=['has_cancer', 'is_healthy'],\n",
    "                         columns=['predicted_cancer','predicted_healthy'])\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, we may be particularly interested in minimizing the false positive rate, aka reducing the chance that a patient with cancer is diagnosed as healthy.\n",
    "\n",
    "In order to do this, we can **lower the threshold for predicting class 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   class_0_pp  class_1_pp  pred_class_thresh50  pred_class_thresh10\n",
      "0    0.896571    0.103429                    0                    1\n",
      "1    0.086331    0.913669                    1                    1\n",
      "2    0.312713    0.687287                    1                    1\n",
      "3    0.920883    0.079117                    0                    0\n",
      "4    0.356408    0.643592                    1                    1\n",
      "5    0.876881    0.123119                    0                    1\n",
      "6    0.920883    0.079117                    0                    0\n",
      "7    0.913423    0.086577                    0                    0\n",
      "8    0.312713    0.687287                    1                    1\n",
      "9    0.133763    0.866237                    1                    1\n"
     ]
    }
   ],
   "source": [
    "Y_pp['pred_class_thresh10'] = [1 if x >= 0.10 else 0 for x in Y_pp.class_1_pp.values]\n",
    "print(Y_pp.iloc[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will reduce our false negative rate to 0, but at the expense of our false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            predicted_cancer  predicted_healthy\n",
      "has_cancer                79                  0\n",
      "is_healthy                79                 68\n"
     ]
    }
   ],
   "source": [
    "conmat_10 = np.array(confusion_matrix(Y_test, Y_pp.pred_class_thresh10.values, labels=[1,0]))\n",
    "\n",
    "confusion_10 = pd.DataFrame(conmat_10, index=['has_cancer', 'is_healthy'],\n",
    "                            columns=['predicted_cancer','predicted_healthy'])\n",
    "\n",
    "print(confusion_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful way to visualize these tradeoffs is with **area under the curve (AUC)** graphs. The most popular AUC graph is the **reciever operating characteristic (ROC)** curve.\n",
    "\n",
    "The ROC curve compares the true positive rate against the false positive rate. It is unaffected by the distribution of class labels since it is only comparing the correct vs. incorrect label assignments for one class.\n",
    "\n",
    "To plot this we will use the roc_curve() and auc() functions from sklearn. We will also use the decision_function() method of the logistic regression, which essentiall gives us the confidence of each observation being in one class or another.\n",
    "\n",
    "(Plotting is the nearly the same as in the scikit learn documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -2.15969287e+00   2.35928577e+00   7.87467110e-01  -2.45440887e+00\n",
      "   5.90989778e-01  -1.96321554e+00  -2.45440887e+00  -2.35617020e+00\n",
      "   7.87467110e-01   1.86809244e+00  -2.35617020e+00   2.16280843e+00\n",
      "  -2.25793154e+00  -2.35617020e+00  -1.86497687e+00   7.87467110e-01\n",
      "  -1.27554488e+00   7.87467110e-01  -2.25793154e+00  -1.47202221e+00\n",
      "   1.27866044e+00  -2.55264754e+00   1.08218311e+00   1.98035113e-01\n",
      "  -2.15969287e+00  -2.15969287e+00  -1.94919551e-01  -3.91396883e-01\n",
      "  -2.35617020e+00  -2.55264754e+00   1.55778134e-03  -1.96321554e+00\n",
      "  -1.96321554e+00  -1.76673821e+00   3.34167243e+00  -2.65088620e+00\n",
      "   2.96273779e-01   2.16280843e+00   3.34167243e+00   3.24343376e+00\n",
      "  -2.06145421e+00  -1.94919551e-01   1.67161510e+00   1.55778134e-03\n",
      "  -2.06145421e+00  -1.96321554e+00  -1.76673821e+00  -2.15969287e+00\n",
      "   2.26104710e+00  -2.55264754e+00  -2.35617020e+00  -2.35617020e+00\n",
      "  -2.15969287e+00  -2.15969287e+00  -2.06145421e+00   1.96633110e+00\n",
      "   2.65400176e+00   2.45752443e+00  -2.35617020e+00  -2.15969287e+00\n",
      "  -2.25793154e+00   3.73462709e+00   2.65400176e+00  -2.35617020e+00\n",
      "  -1.57026088e+00  -2.45440887e+00   5.90989778e-01  -9.66808847e-02\n",
      "  -2.45440887e+00  -2.45440887e+00  -4.89635549e-01   2.26104710e+00\n",
      "  -1.66849954e+00  -2.15969287e+00  -3.91396883e-01  -2.45440887e+00\n",
      "  -2.06145421e+00  -2.45440887e+00  -2.35617020e+00  -2.35617020e+00\n",
      "   1.18042177e+00  -2.15969287e+00  -2.45440887e+00  -1.76673821e+00\n",
      "   1.08218311e+00  -2.25793154e+00  -8.82590213e-01   1.47513777e+00\n",
      "  -2.35617020e+00  -1.86497687e+00  -2.45440887e+00   1.57337644e+00\n",
      "  -2.15969287e+00  -6.86112881e-01   2.06456977e+00  -1.76673821e+00\n",
      "  -7.84351547e-01  -2.55264754e+00  -1.37378354e+00   3.04695643e+00\n",
      "  -2.25793154e+00  -2.35617020e+00   2.65400176e+00   2.75224043e+00\n",
      "  -2.15969287e+00   4.32405909e+00  -2.06145421e+00   4.92751111e-01\n",
      "   3.04695643e+00   3.34167243e+00  -2.35617020e+00  -1.96321554e+00\n",
      "   2.75224043e+00   2.65400176e+00  -7.84351547e-01   1.08218311e+00\n",
      "  -2.15969287e+00  -1.76673821e+00   1.67161510e+00  -2.25793154e+00\n",
      "  -2.35617020e+00  -2.25793154e+00  -8.82590213e-01   1.86809244e+00\n",
      "  -2.45440887e+00   2.65400176e+00   1.47513777e+00  -2.25793154e+00\n",
      "   1.37689911e+00  -1.76673821e+00  -2.45440887e+00   2.96273779e-01\n",
      "  -2.45440887e+00  -1.96321554e+00  -2.15969287e+00  -1.86497687e+00\n",
      "  -1.96321554e+00  -2.06145421e+00  -1.86497687e+00  -1.27554488e+00\n",
      "  -2.15969287e+00  -2.06145421e+00  -2.15969287e+00  -2.06145421e+00\n",
      "  -2.45440887e+00   2.65400176e+00  -2.15969287e+00  -2.25793154e+00\n",
      "  -2.25793154e+00  -1.86497687e+00  -1.66849954e+00   1.37689911e+00\n",
      "  -2.35617020e+00  -2.25793154e+00  -2.25793154e+00   4.92751111e-01\n",
      "  -2.25793154e+00   1.55778134e-03  -2.45440887e+00  -2.35617020e+00\n",
      "  -2.45440887e+00   4.52053642e+00  -2.55264754e+00  -2.15969287e+00\n",
      "  -2.35617020e+00   7.87467110e-01  -2.06145421e+00  -2.06145421e+00\n",
      "  -2.15969287e+00  -1.76673821e+00  -9.66808847e-02   2.65400176e+00\n",
      "  -1.96321554e+00  -2.25793154e+00  -2.55264754e+00  -1.86497687e+00\n",
      "   2.35928577e+00   2.06456977e+00  -2.25793154e+00  -2.65088620e+00\n",
      "   1.55778134e-03   2.96273779e-01  -2.25793154e+00  -1.86497687e+00\n",
      "  -2.15969287e+00  -2.15969287e+00   5.90989778e-01  -2.25793154e+00\n",
      "  -1.96321554e+00   2.55576310e+00  -4.89635549e-01  -2.25793154e+00\n",
      "  -2.55264754e+00  -2.35617020e+00  -2.45440887e+00  -1.76673821e+00\n",
      "   9.83944442e-01  -2.35617020e+00  -2.15969287e+00  -2.25793154e+00\n",
      "  -1.57026088e+00   5.90989778e-01  -2.35617020e+00  -1.37378354e+00\n",
      "   1.76985377e+00   2.45752443e+00  -2.15969287e+00   4.02934309e+00\n",
      "   1.08218311e+00   3.43991109e+00  -2.06145421e+00   3.34167243e+00\n",
      "   2.45752443e+00   7.87467110e-01  -2.35617020e+00  -2.06145421e+00\n",
      "  -1.94919551e-01  -2.25793154e+00  -2.15969287e+00   9.83944442e-01\n",
      "  -2.25793154e+00   2.96273779e-01  -1.76673821e+00  -1.96321554e+00\n",
      "  -2.35617020e+00  -1.86497687e+00]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "Y_score = logreg.decision_function(X_test) #predict confidence score for samples\n",
    "\n",
    "\n",
    "# FPR = dict()  #creates 3 empty dictionaries\n",
    "# TPR = dict()\n",
    "# ROC_AUC = dict()\n",
    "\n",
    "# # For class 1, find the area under the curve\n",
    "# FPR[1], TPR[1], _ = roc_curve(Y_test, Y_score)\n",
    "# ROC_AUC[1] = auc(FPR[1], TPR[1])\n",
    "\n",
    "# # Plot of a ROC curve for class 1 (has_cancer)\n",
    "# plt.figure(figsize=[11,9])\n",
    "# plt.plot(FPR[1], TPR[1], label='ROC curve (area = %0.2f)' % ROC_AUC[1], linewidth=4)\n",
    "# plt.plot([0, 1], [0, 1], 'k--', linewidth=4)\n",
    "# plt.xlim([0.0, 1.0])\n",
    "# plt.ylim([0.0, 1.05])\n",
    "# plt.xlabel('False Positive Rate', fontsize=18)\n",
    "# plt.ylabel('True Positive Rate', fontsize=18)\n",
    "# plt.title('Receiver operating characteristic for cancer detection', fontsize=18)\n",
    "# plt.legend(loc=\"lower right\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the intuition for the ROC curve?\n",
    "\n",
    "As the class assignment threshold increases for the positive class (has cancer), the false positive rate and true positive rate necessarily increase. For a classifier performing at chance, this would be the diagonal dotted line: an equal chance of false positives and true positives. \n",
    "\n",
    "The greater the area under the curve, the higher the ratio of true positives to false positives as the threshold becomes more lenient. Thus, the greater the area under the curve, the higher the quality of the classification model. In the Wisconsin breast cancer data the area under the curve is 0.99, indicating a nearly perfect model. Most classification problems will never get close to this!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
